# -*- org-export-babel-evaluate: t; -*-
#+TITLE: Experiment Diary
#+LANGUAGE: en 
#+STARTUP: indent
#+STARTUP: logdrawer hideblocks
#+SEQ_TODO: TODO INPROGRESS(i) | DONE DEFERRED(@) CANCELED(@)
#+TAGS: @JULIO(J)
#+TAGS: IMPORTANT(i) TEST(t) DEPRECATED(d) noexport(n) ignore(n) export(e)
#+CATEGORY: exp
#+OPTIONS: ^:{} todo:nil H:4
#+PROPERTY: header-args :cache no :eval no-export 


* Description 

Benchnark insertion time
- PMQ / GEOHASH
- BTREE -
- RTREE -  Quadratic algorithm 
- Dense vector

Number of insertions: 
elements of size 32 bytes:
- Key = 8 bytes
- Value = (19) aligned to 24 Bytes

- PMA batch size = 1000

+350 million elements = src_python{ return ( 32 * 350 * 10**6 / 2**30) } {{{results(=10.43081283569336=)}}} GB .+

Will use a PMA of 16 GB 
#+begin_src python :results output :exports both
print( 536870912 * 32 / 2**30)
#+end_src

#+RESULTS:
: 16.0

:UPDATE:
The 350 M elements benchmark takes to long, mainly due to to the global scan operations done after each insertion.

We will re-run this experiment with 10 M elements. Batch of size 1000. 
To test with 350 we should disable the scans. 
:END:

** Standalone script                                              :noexport:
To generate the results outside emacs and orgmode you can use the standalone scripts, generated from the tangled source blocks in this file

- parse.sh : parse the results to CSV
- plotResults.R : generate the plots 
  

* INPROGRESS Experiment Script
** DONE Initial Setup

#+begin_src sh :results value :exports both
expId=$(basename $(pwd))
echo $expId
#+end_src

#+NAME: expId
#+RESULTS:
: exp20170919161448

Set up git branch
#+begin_src sh :results output :exports both :var expId=expId
git checkout master
git commit -m "LBK: add ${expId} entry" ../../../LabBook.org
#+end_src

#+RESULTS:
: M	LabBook.org
: M	benchmarks/bench_insert_and_scan.cpp
: Your branch is up-to-date with 'origin/master'.
: [master 1c0a8df] LBK: add exp20170919161448 entry
:  1 file changed, 19 insertions(+), 11 deletions(-)

Create EXP branch
#+begin_src sh :results output :exports both :var expId=expId
git checkout -b $expId
#+end_src

#+RESULTS:

Commit branch
#+begin_src sh :results output :exports both :var expId=expId
git status .
git add exp.org
git commit -m "Initial commit for $expId"
#+end_src

#+RESULTS:
#+begin_example
On branch exp20170919161448
Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git checkout -- <file>..." to discard changes in working directory)

	modified:   exp.org

Untracked files:
  (use "git add <file>..." to include in what will be committed)

	run.sh

no changes added to commit (use "git add" and/or "git commit -a")
[exp20170919161448 37950cc] Initial commit for exp20170919161448
 1 file changed, 14 insertions(+), 11 deletions(-)
#+end_example

#+begin_src sh :results output :exports both :var expId=expId
git la -3 
#+end_src

#+RESULTS:
: * ae8f92f (HEAD -> exp20170919161448) test dense vector at last
: * 778294e Initial commit for exp20170919161448
: * ce6f828 Initial commit for exp20170919161448


** DONE Export run script

Use C-u C-c C-v t to tangle this script 
#+begin_src sh :results output :exports both :tangle run.sh :shebang #!/bin/bash :eval never :var expId=expId
set -e
# Any subsequent(*) commands which fail will cause the shell script to exit immediately
echo $(hostname) 

##########################################################
### SETUP THIS VARIABLES

BUILDIR=~/Projects/pmq/build-release
PMABUILD_DIR=~/Projects/hppsimulations/build-release
DATADIR=$(pwd)
# workaround as :var arguments are not been correctly tangled by my orgmode
#expId=$(basename $(pwd) | sed 's/exp//g')
expId=$(basename $(pwd))
TMPDIR=/dev/shm/$expId

# generate output name
if [ $1 ] ; then 
    EXECID=$1
else
    EXECID=$(date +%s)
fi

#########################################################

mkdir -p $TMPDIR
#mkdir -p $DATADIR

# make pma
mkdir -p $PMABUILD_DIR
cd $PMABUILD_DIR
cmake -DCMAKE_BUILD_TYPE="Release" -DTWITTERVIS=OFF -DRHO_INIT=OFF ../pma_cd
make 

# make twitterVis
mkdir -p $BUILDIR
cd $BUILDIR 
cmake -DPMA_BUILD_DIR=$PMABUILD_DIR -DCMAKE_BUILD_TYPE="Release" ..
make

#get machine configuration
echo "" > $DATADIR/info.org
~/Projects/pmq/scripts/g5k_get_info.sh $DATADIR/info.org 

# EXECUTE BENCHMARK

#Continue execution even if one these fails
set +e 
# Queries insert remove count
n=$((10**7))
b=1000
stdbuf -oL ./benchmarks/bench_insert_and_scan -n $n -r 123 -x 3 -b $b > $TMPDIR/bench_insert_and_scan_$n_$b_$EXECID.log

set -e

cd $TMPDIR
tar -cvzf log_$EXECID.tgz *_$EXECID.log

cd $DATADIR
cp $TMPDIR/log_$EXECID.tgz .

git checkout $expId

git add info.org log_$EXECID.tgz run.sh 
git add -u
git commit -m "Finish execution $EXECID"
git push origin $expId
#+end_src 


** DONE Commit local changes
#+begin_src sh :results output :exports both
git status .
#+end_src

#+RESULTS:
#+begin_example
On branch exp20170919161448
Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git checkout -- <file>..." to discard changes in working directory)

	modified:   exp.org

Untracked files:
  (use "git add <file>..." to include in what will be committed)

	.#exp.org
	run.sh

no changes added to commit (use "git add" and/or "git commit -a")
#+end_example

#+begin_src sh :results output :exports both
git add run.sh exp.org
git commit -m "UPD: run.sh script"
#git commit --amend -m "UPD: run.sh script"
#+end_src

#+RESULTS:
: [exp20170919161448 e4d3f76] UPD: run.sh script
:  2 files changed, 71 insertions(+), 4 deletions(-)
:  create mode 100755 data/cicero/exp20170919161448/run.sh

Push to remote
#+begin_src sh :results output :exports both :var expId=expId
#git push bitbucket $expId
git push origin $expId
#+end_src

#+RESULTS:

** Local Execution                                                   :local:ARCHIVE:

#+begin_src sh :results output :exports both :session local :var expId=expId
cd ~/Projects/pmq/data/$(hostname)/$expId
runid=$(date +%s)
tmux new -d -s runExp "cd ~/Projects/pmq/data/$(hostname)/$expId; ./run.sh ${runid} &> run_${runid}"
git add run_$runid
echo $runid
#+end_src

Check process running
#+begin_src sh :results output :exports both :session remote
tmux ls
ps ux
#+end_src

** INPROGRESS Remote Execution                                      :remote:

*** Get new changes on remote                                      :remote:
#+begin_src sh :session remote :results output :exports both 
ssh -A cicero
#+end_src

#+RESULTS:
#+begin_example

Welcome to Ubuntu 16.04.3 LTS (GNU/Linux 4.4.0-92-generic x86_64)

 ,* Documentation:  https://help.ubuntu.com
 ,* Management:     https://landscape.canonical.com
 ,* Support:        https://ubuntu.com/advantage

44 packages can be updated.
0 updates are security updates.

,*** System restart required ***
Last login: Wed Sep 20 14:32:44 2017 from 143.54.11.6
#+end_example

Get the last script on the remote machine (require entering a password
for bitbucket)
#+begin_src sh :session remote :results output :exports both :var expId=expId
cd ~/Projects/pmq/
git config --add remote.origin.fetch refs/heads/$expId:refs/remotes/origin/$expId
git fetch origin $expId
git checkout $expId
git pull origin $expId
git log -1 | cat 
#+end_src

#+RESULTS:
#+begin_example

julio@cicero:~/Projects/pmq$ julio@cicero:~/Projects/pmq$ remote: Counting objects: 18, done.
(1/15)           remote: Compressing objects:  13% (2/15)           remote: Compressing objects:  20% (3/15)           remote: Compressing objects:  26% (4/15)           remote: Compressing objects:  33% (5/15)           remote: Compressing objects:  40% (6/15)           remote: Compressing objects:  46% (7/15)           remote: Compressing objects:  53% (8/15)           remote: Compressing objects:  60% (9/15)           remote: Compressing objects:  66% (10/15)           remote: Compressing objects:  73% (11/15)           remote: Compressing objects:  80% (12/15)           remote: Compressing objects:  86% (13/15)           remote: Compressing objects:  93% (14/15)           remote: Compressing objects: 100% (15/15)           remote: Compressing objects: 100% (15/15), done.        
remote: Total 18 (delta 10), reused 0 (delta 0)
(1/18)   Unpacking objects:  11% (2/18)   Unpacking objects:  16% (3/18)   Unpacking objects:  22% (4/18)   Unpacking objects:  27% (5/18)   Unpacking objects:  33% (6/18)   Unpacking objects:  38% (7/18)   Unpacking objects:  44% (8/18)   Unpacking objects:  50% (9/18)   Unpacking objects:  55% (10/18)   Unpacking objects:  61% (11/18)   Unpacking objects:  66% (12/18)   Unpacking objects:  72% (13/18)   Unpacking objects:  77% (14/18)   Unpacking objects:  83% (15/18)   Unpacking objects:  88% (16/18)   Unpacking objects:  94% (17/18)   Unpacking objects: 100% (18/18)   Unpacking objects: 100% (18/18), done.
From bitbucket.org:jtoss/pmq
FETCH_HEAD
origin/exp20170919161448
Already on 'exp20170919161448'
Your branch is behind 'origin/exp20170919161448' by 3 commits, and can be fast-forwarded.
  (use "git pull" to update your local branch)
From bitbucket.org:jtoss/pmq
FETCH_HEAD
Updating ab0bee4..b9c4a96
Fast-forward
 data/cicero/exp20170919161448/exp.org | 92 +++++++++++++++++++++--------------
 data/cicero/exp20170919161448/run.sh  |  4 +-
 2 files changed, 58 insertions(+), 38 deletions(-)
commit b9c4a967da9b70e14c827639a3f371078db6464f
Date:   Wed Sep 20 15:10:23 2017 -0300

    TODO: rerun with 10 M elements
#+end_example

Update PMA repository on exp machine
#+begin_src sh :session remote :results output :exports both :var expId=expId
cd ~/Projects/hppsimulations/
git pull origin PMA_2016
git log -1 | cat
#+end_src

#+RESULTS:
: 
: julio@cicero:~/Projects/hppsimulations$ From bitbucket.org:joaocomba/pma
: FETCH_HEAD
: Already up-to-date.
: commit 6931408d8b9c109f3f2a9543374cfd712791b1e7
: Date:   Tue Sep 19 16:58:38 2017 -0300
: 
:     error ouput on pma initialization

*** Execute Remotely                                               :remote:

Opens ssh connection and a tmux session

#+begin_src sh :results output :exports both :session remote :var expId=expId
cd ~/Projects/pmq/data/cicero/$expId
runid=$(date +%s)
tmux new -d -s runExp "cd ~/Projects/pmq/data/cicero/$expId; ./run.sh ${runid} &> run_${runid}"
git add run_$runid
echo $runid
#+end_src

#+RESULTS:
: 
: julio@cicero:~/Projects/pmq/data/cicero/exp20170919161448$ julio@cicero:~/Projects/pmq/data/cicero/exp20170919161448$ julio@cicero:~/Projects/pmq/data/cicero/exp20170919161448$ julio@cicero:~/Projects/pmq/data/cicero/exp20170919161448$ 1505933858

Check process running
#+begin_src sh :results output :exports both :session remote
tmux ls
ps ux
#+end_src

#+RESULTS:
#+begin_example
runExp: 1 windows (created Wed Sep 20 15:57:38 2017) [80x23]
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
julio     3002  0.0  0.0  45248  4604 ?        Ss   14:32   0:00 /lib/systemd/sy
julio     3004  0.0  0.0 145364  2112 ?        S    14:32   0:00 (sd-pam)
julio     3054  0.0  0.0  97464  3472 ?        S    14:32   0:00 sshd: julio@pts
julio     3055  0.0  0.0  23700  6496 pts/8    Ss+  14:32   0:00 -bash
julio     3273  0.0  0.0  97464  3416 ?        S    15:57   0:00 sshd: julio@pts
julio     3274  0.0  0.0  22688  5360 pts/9    Ss   15:57   0:00 -bash
julio     3323  0.0  0.0  29420  2952 ?        Ss   15:57   0:00 tmux new -d -s 
julio     3324  0.0  0.0  12532  3024 pts/10   Ss+  15:57   0:00 bash -c cd ~/Pr
julio     3326  0.0  0.0  12536  3028 pts/10   S+   15:57   0:00 /bin/bash ./run
julio     3335  0.0  0.0   9676  2324 pts/10   S+   15:57   0:00 make
julio     3338  0.0  0.0   9676  2348 pts/10   S+   15:57   0:00 make -f CMakeFi
julio     3504  0.0  0.0   9676  2364 pts/10   S+   15:57   0:00 make -f tests/C
julio     3507  0.0  0.0   4508   760 pts/10   S+   15:57   0:00 /bin/sh -c cd /
julio     3508  0.0  0.0   8352   700 pts/10   S+   15:57   0:00 /usr/bin/c++ -I
julio     3509  0.0  0.2 125540 87696 pts/10   R+   15:57   0:00 /usr/lib/gcc/x8
julio     3511  0.0  0.0  37368  3316 pts/9    R+   15:57   0:00 ps ux
#+end_example

**** TODO Pull local 
#+begin_src sh :results output :exports both :var expId=expId
git commit -a -m "wip"
git status
git pull --rebase origin $expId
#+end_src

#+RESULTS:
#+begin_example
[exp20170907112116 b3f673f] wip
 1 file changed, 8 insertions(+), 14 deletions(-)
On branch exp20170907112116
Untracked files:
  (use "git add <file>..." to include in what will be committed)

	../../../LabBook.org.orig
	../../../benchmarks/bench_insert_and_scan.cpp.orig
	../../../build-Release/
	../exp20170904153555/
	../exp20170907105314/
	../exp20170907105804/
	.#exp.org
	img/
	nil.csv
	teste.csv

nothing added to commit but untracked files present (use "git add" to track)
First, rewinding head to replay your work on top of it...
Applying: wip experiment
Applying: wip
#+end_example


* TODO Analisys
** Generate csv files
:PROPERTIES: 
:HEADER-ARGS:sh: :tangle parse.sh :shebang #!/bin/bash
:END:      

List logFiles
#+begin_src sh :results table :exports both
ls -htl *tgz
#+end_src

#+RESULTS:
| -rw-rw-r-- 1 julio julio 1018K Set  7 12:35 log_1504795600.tgz |

#+NAME: logFile
#+begin_src sh :results output :exports both 
tar xvzf log_1504795600.tgz
#+end_src

#+RESULTS: logFile
: bench_insert_and_scan_1504795600.log

Create CSV using logFile 
#+begin_src sh :results output :exports both :var logFile=logFile[0]
#echo $logFile
echo $(basename -s .log $logFile ).csv
grep "GeoHashBinary\|BTree\|RTree ;" $logFile | sed "s/InsertionBench//g" >  $(basename -s .log $logFile ).csv
#+end_src

#+NAME: csvFile
#+RESULTS:
: bench_insert_and_scan_1504795600.csv

Create an director for images
#+begin_src sh :results output :exports both :tangle no
mkdir img
#+end_src

#+RESULTS:

** Results
:PROPERTIES: 
:HEADER-ARGS:R: :session *R* :tangle plotResults.R :shebang #!/usr/bin/env Rscript
:END:      

Load the CSV into R
#+begin_src R :results output :exports both :var f=csvFile
library(tidyverse)

df <- f[[1]] %>%
    read_delim(delim=";",trim_ws = TRUE, col_names = paste("V",c(1:8),sep="") )

str(df)

#+end_src

#+RESULTS:
#+begin_example
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_integer(),
  V3 = col_character(),
  V4 = col_double(),
  V5 = col_character(),
  V6 = col_integer(),
  V7 = col_character(),
  V8 = col_integer()
)
Warning: 150000 parsing failures.
row # A tibble: 5 x 5 col     row   col  expected    actual                                   file expected   <int> <chr>     <chr>     <chr>                                  <chr> actual 1     1  <NA> 8 columns 5 columns 'bench_insert_and_scan_1504795600.csv' file 2     2  <NA> 8 columns 7 columns 'bench_insert_and_scan_1504795600.csv' row 3     3  <NA> 8 columns 7 columns 'bench_insert_and_scan_1504795600.csv' col 4     4  <NA> 8 columns 7 columns 'bench_insert_and_scan_1504795600.csv' expected 5     5  <NA> 8 columns 9 columns 'bench_insert_and_scan_1504795600.csv'
... ................. ... ........................................................................ ........ ........................................................................ ...... ........................................................................ .... ........................................................................ ... ......................................................... [... truncated]
Warning message:
In rbind(names(probs), probs_f) :
  number of columns of result is not a multiple of vector length (arg 1)
Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	150000 obs. of  8 variables:
 $ V1: chr  "GeoHashBinary" "GeoHashBinary" "GeoHashBinary" "GeoHashBinary" ...
 $ V2: int  0 0 0 0 0 1 1 1 1 1 ...
 $ V3: chr  "insert" "scan_at_region" "scan_at_region" "scan_at_region" ...
 $ V4: num  0.018055 0.00046 0.000476 0.000448 0.00195 ...
 $ V5: chr  NA "scan_at_region_refinements" "scan_at_region_refinements" "scan_at_region_refinements" ...
 $ V6: int  NA 1 1 1 1 NA 1 1 1 1 ...
 $ V7: chr  NA NA NA NA ...
 $ V8: int  NA NA NA NA 100 NA NA NA NA 200 ...
 - attr(*, "problems")=Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	150000 obs. of  5 variables:
  ..$ row     : int  1 2 3 4 5 6 7 8 9 10 ...
  ..$ col     : chr  NA NA NA NA ...
  ..$ expected: chr  "8 columns" "8 columns" "8 columns" "8 columns" ...
  ..$ actual  : chr  "5 columns" "7 columns" "7 columns" "7 columns" ...
  ..$ file    : chr  "'bench_insert_and_scan_1504795600.csv'" "'bench_insert_and_scan_1504795600.csv'" "'bench_insert_and_scan_1504795600.csv'" "'bench_insert_and_scan_1504795600.csv'" ...
 - attr(*, "spec")=List of 2
  ..$ cols   :List of 8
  .. ..$ V1: list()
  .. .. ..- attr(*, "class")= chr  "collector_character" "collector"
  .. ..$ V2: list()
  .. .. ..- attr(*, "class")= chr  "collector_integer" "collector"
  .. ..$ V3: list()
  .. .. ..- attr(*, "class")= chr  "collector_character" "collector"
  .. ..$ V4: list()
  .. .. ..- attr(*, "class")= chr  "collector_double" "collector"
  .. ..$ V5: list()
  .. .. ..- attr(*, "class")= chr  "collector_character" "collector"
  .. ..$ V6: list()
  .. .. ..- attr(*, "class")= chr  "collector_integer" "collector"
  .. ..$ V7: list()
  .. .. ..- attr(*, "class")= chr  "collector_character" "collector"
  .. ..$ V8: list()
  .. .. ..- attr(*, "class")= chr  "collector_integer" "collector"
  ..$ default: list()
  .. ..- attr(*, "class")= chr  "collector_guess" "collector"
  ..- attr(*, "class")= chr "col_spec"
#+end_example

Remove useless columns
#+begin_src R :results output :exports both :session 

names(df) <- c("algo", "id", "bench" , "time" , "V5" , "V6"  , "V7" , "count")

df <- select(df, -V5, -V6, -V7)
df
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 150,000 x 5
            algo    id           bench     time count
           <chr> <int>           <chr>    <dbl> <int>
 1 GeoHashBinary     0          insert 0.018055    NA
 2 GeoHashBinary     0  scan_at_region 0.000460    NA
 3 GeoHashBinary     0  scan_at_region 0.000476    NA
 4 GeoHashBinary     0  scan_at_region 0.000448    NA
 5 GeoHashBinary     0 apply_at_region 0.001950   100
 6 GeoHashBinary     1          insert 0.013157    NA
 7 GeoHashBinary     1  scan_at_region 0.000809    NA
 8 GeoHashBinary     1  scan_at_region 0.000797    NA
 9 GeoHashBinary     1  scan_at_region 0.000769    NA
10 GeoHashBinary     1 apply_at_region 0.000585   200
# ... with 149,990 more rows
#+end_example

Summary of the data frame
#+begin_src R :results output :session :exports both
summary(df[df$algo=="GeoHashBinary",])
summary(df[df$algo=="BTree",])
summary(df[df$algo=="RTree",])
#+end_src

#+RESULTS:
#+begin_example
     algo                 id          bench                time         
 Length:50000       Min.   :   0   Length:50000       Min.   : 0.00024  
 Class :character   1st Qu.:2500   Class :character   1st Qu.: 0.08270  
 Mode  :character   Median :5000   Mode  :character   Median : 0.77856  
                    Mean   :5000                      Mean   : 1.72410  
                    3rd Qu.:7499                      3rd Qu.: 3.15301  
                    Max.   :9999                      Max.   :14.36430  
                                                                        
     count        
 Min.   :    100  
 1st Qu.: 250075  
 Median : 500050  
 Mean   : 500050  
 3rd Qu.: 750025  
 Max.   :1000000  
 NA's   :40000
     algo                 id          bench                time        
 Length:50000       Min.   :   0   Length:50000       Min.   : 0.0007  
 Class :character   1st Qu.:2500   Class :character   1st Qu.: 0.2962  
 Mode  :character   Median :5000   Mode  :character   Median : 4.5789  
                    Mean   :5000                      Mean   : 5.6744  
                    3rd Qu.:7499                      3rd Qu.: 9.7199  
                    Max.   :9999                      Max.   :19.0842  
                                                                       
     count        
 Min.   :    100  
 1st Qu.: 250075  
 Median : 500050  
 Mean   : 500050  
 3rd Qu.: 750025  
 Max.   :1000000  
 NA's   :40000
     algo                 id          bench                time          
 Length:50000       Min.   :   0   Length:50000       Min.   : 0.000969  
 Class :character   1st Qu.:2500   Class :character   1st Qu.: 0.797774  
 Mode  :character   Median :5000   Mode  :character   Median : 8.138380  
                    Mean   :5000                      Mean   : 9.244019  
                    3rd Qu.:7499                      3rd Qu.:17.638125  
                    Max.   :9999                      Max.   :24.549800  
                                                                         
     count      
 Min.   : NA    
 1st Qu.: NA    
 Median : NA    
 Mean   :NaN    
 3rd Qu.: NA    
 Max.   : NA    
 NA's   :50000
#+end_example

*** Overview of results                                                :plot:

Plot an overview of every benchmark , doing average of times. 
#+begin_src R :results output :exports both
df %>% group_by(algo,id,bench, count) %>%
    summarize(ms = mean(time), stdv = sd(time)) -> dfplot

dfplot
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 90,000 x 6
# Groups:   algo, id, bench [?]
    algo    id           bench count          ms         stdv
   <chr> <int>           <chr> <int>       <dbl>        <dbl>
 1 BTree     0 apply_at_region   100 0.000945000           NA
 2 BTree     0          insert    NA 0.007075000           NA
 3 BTree     0  scan_at_region    NA 0.000775000 7.238094e-05
 4 BTree     1 apply_at_region   200 0.000700000           NA
 5 BTree     1          insert    NA 0.007709000           NA
 6 BTree     1  scan_at_region    NA 0.001430667 9.814955e-06
 7 BTree     2 apply_at_region   300 0.000763000           NA
 8 BTree     2          insert    NA 0.006893000           NA
 9 BTree     2  scan_at_region    NA 0.002117000 5.196152e-06
10 BTree     3 apply_at_region   400 0.000829000           NA
# ... with 89,990 more rows
#+end_example

#+begin_src R :results output graphics :file "./img/overview.png" :exports both :width 800 :height 600
library(ggplot2)

dfplot %>% 
#    ungroup %>% 
 #   mutate(bench = revalue( bench, c("apply_at_region" = "count"))) %>% 
ggplot(aes(x=id,y=ms, color=factor(algo))) + 
    geom_line() +
    #geom_errorbar(aes(ymin = ms - stdv, ymax = ms + stdv), width = 0.3 ) +
    facet_wrap(~bench, scales="free",ncol=1,labeller=labeller(bench=c(apply_at_region="Global Count", insert="Insertion", scan_at_region="Golbal scan")))
#+end_src

#+RESULTS:
[[file:./img/overview.png]]

*** DONE Insertion performance

#+begin_src R :results output :exports both :session 
 dfplot %>% filter( bench == "insert") -> dfinsert
#+end_src

#+RESULTS:

**** Overall                                                        :plot:
#+begin_src R :results output graphics :file "./img/overallInsertion.png" :exports both :width 600 :height 400
dfinsert %>%
ggplot(aes(x=id,y=ms, color=factor(algo))) + 
geom_line() +
labs(title = "Insertions") + 
facet_wrap(~algo, scales="free", ncol=1)
#+end_src

#+RESULTS:
[[file:./img/overallInsertion.png]]

Total insertion time:
#+begin_src R :results append :session :exports both
dfinsert %>% 
    group_by(algo) %>%
    summarize(Avergae = mean(ms), Total = sum(ms))

#+end_src

#+RESULTS:
:            algo    Average      Total
: 1         BTree 0.05150084   515.0084
: 2 GeoHashBinary 0.10885076  1088.5076
: 3         RTree 1.24829441 12482.9441
| BTree         |   0.03546119 |   354.6119 |
| GeoHashBinary | 0.0793330121 | 793.330121 |
| RTree         |  0.586476944 | 5864.76944 |
| BTree         |   0.03546119 |   354.6119 |
| GeoHashBinary | 0.0793330121 | 793.330121 |
| RTree         |  0.586476944 | 5864.76944 |

**** Amortized time

We compute tree time:
- individual insertion time for each batch
- accumulated time at batch #k
- ammortized time : average of the past times at batch #k

#+begin_src R :results output :exports both
avgTime = cbind(dfinsert, 
                sumTime=c(lapply(split(dfinsert, dfinsert$algo), function(x) cumsum(x$ms)), recursive=T),
                avgTime=c(lapply(split(dfinsert, dfinsert$algo), function(x) cumsum(x$ms)/(x$id+1)), recursive=T)
                )
#+end_src

#+RESULTS:
: # A tibble: 3 x 3
:            algo    Avergae     Total
:           <chr>      <dbl>     <dbl>
: 1         BTree 0.03546119  354.6119
: 2 GeoHashBinary 0.07933301  793.3301
: 3         RTree 0.58647694 5864.7694

***** Melting the data (time / avgTime)
We need to melt the time columns to be able to plot as a grid

#+begin_src R :results output :exports both :session 
avgTime %>% 
    select(-count,-stdv) %>%
    gather(stat, value, ms, sumTime, avgTime) -> melted_times

melted_times
#+end_src

#+RESULTS:
#+begin_example
Warning message:
attributes are not identical across measure variables;
they will be dropped
# A tibble: 90,000 x 5
# Groups:   algo, id, bench [30,000]
    algo    id  bench  stat    value
   <chr> <int>  <chr> <chr>    <dbl>
 1 BTree     0 insert    ms 0.007075
 2 BTree     1 insert    ms 0.007709
 3 BTree     2 insert    ms 0.006893
 4 BTree     3 insert    ms 0.006529
 5 BTree     4 insert    ms 0.006903
 6 BTree     5 insert    ms 0.006266
 7 BTree     6 insert    ms 0.006714
 8 BTree     7 insert    ms 0.007016
 9 BTree     8 insert    ms 0.006645
10 BTree     9 insert    ms 0.007688
# ... with 89,990 more rows
#+end_example

***** Comparison Time X avgTime                                    :plot:
#+begin_src R :results output graphics :file "./img/grid_times.png" :exports both :width 600 :height 400 
melted_times %>%
    ggplot(aes(x=id,y=value,color=factor(algo))) +
geom_line() + 
facet_grid(stat~algo,scales="free", labeller=labeller(stat=label_value))
#facet_wrap(variable~algo,scales="free", labeller=labeller(variable=label_value))
#+end_src

#+RESULTS:
[[file:./img/grid_times.png]]

**** Zoom View                                                      :plot:

#+begin_src R :results output graphics :file "./img/Zoom.png" :exports both :width 600 :height 400
avgTime %>% 
    ggplot(aes(x=id, color=factor(algo))) + 
    labs(title="Insertions") +
    geom_point(aes(y=ms), alpha=1) +
#    geom_line(aes(y=avgTime)) + 
    ylim(0,1) 
#+end_src

#+RESULTS:
[[file:./img/Zoom.png]]

