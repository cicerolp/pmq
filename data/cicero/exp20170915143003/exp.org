# -*- org-export-babel-evaluate: t; -*-
#+TITLE: Benchmark Queries 
#+LANGUAGE: en 
#+STARTUP: indent
#+STARTUP: logdrawer hideblocks
#+SEQ_TODO: TODO INPROGRESS(i) | DONE DEFERRED(@) CANCELED(@)
#+TAGS: @JULIO(J)
#+TAGS: IMPORTANT(i) TEST(t) DEPRECATED(d) noexport(n) ignore(n) export(e)
#+CATEGORY: exp
#+OPTIONS: ^:{} todo:nil H:4 toc:t tags:nil author:nil
#+PROPERTY: header-args :cache no :eval never-export 


* DONE Description                                                   :export:

Test the queries on uniform data. 
And compare the following performances.

- PMQ / GEOHASH
- BTREE 
- RTREE - quadratic algorithm 
- RTREE - quadratic algorithm with bulk loading

Use the refinement level = 8 

Elements:
- Timewindow = 26000
- Batch size = 1000

- Total elements = 26.000.000 
** Standalone script                                              :noexport:
To generate the results outside emacs and orgmode you can use the standalone scripts, generated from the tangled source blocks in this file

- parse.sh : parse the results to CSV
- plotResults.R : generate the plots 
  

* DONE Experiment Script
** DONE Initial Setup 

#+begin_src sh :results value :exports both
expId=$(basename $(pwd))
echo $expId
#+end_src

#+NAME: expId
#+RESULTS:
: exp20170915143003

Set up git branch
#+begin_src sh :results output :exports both
git checkout master
#+end_src

#+RESULTS:
: M	LabBook.org

Create EXP branch
#+begin_src sh :results output :exports both :var expId=expId
git checkout -b $expId
#+end_src

#+RESULTS:
: M	LabBook.org

Commit branch
#+begin_src sh :results output :exports both :var expId=expId
git status .
git add exp.org
git commit -m "Initial commit for $expId"
#+end_src

#+RESULTS:
#+begin_example
On branch exp20170915143003
Untracked files:
  (use "git add <file>..." to include in what will be committed)

	.#exp.org
	exp.org
	parse.sh
	plotResults.R
	run.sh

nothing added to commit but untracked files present (use "git add" to track)
[exp20170915143003 1cf746f] Initial commit for exp20170915143003
 1 file changed, 775 insertions(+)
 create mode 100644 data/cicero/exp20170915143003/exp.org
#+end_example

#+begin_src sh :results output :exports both :var expId=expId
git la -3 
#+end_src

#+RESULTS:
: * 1cf746f (HEAD -> exp20170915143003) Initial commit for exp20170915143003
: | * e4b0e35 (origin/exp20170914091842, exp20170914091842) Report exporte in .rst format (preview in bitbucket)
: | * a4a4bba Analysis bench insertions and removals

** DONE Export run script 

Use C-u C-c C-v t to tangle this script 
#+begin_src sh :results output :exports both :tangle run.sh :shebang #!/bin/bash :eval never :var expId=expId
set -e
# Any subsequent(*) commands which fail will cause the shell script to exit immediately
echo $(hostname) 

##########################################################
### SETUP THIS VARIABLES

BUILDIR=~/Projects/pmq/build-release
PMABUILD_DIR=~/Projects/hppsimulations/build-release
DATADIR=$(pwd)
# workaround as :var arguments are not been correctly tangled by my orgmode
#expId=$(basename $(pwd) | sed 's/exp//g')
expId=$(basename $(pwd))
TMPDIR=/dev/shm/$expId

# generate output name
if [ $1 ] ; then 
    EXECID=$1
else
    EXECID=$(date +%s)
fi

#########################################################

mkdir -p $TMPDIR
#mkdir -p $DATADIR

# make pma
mkdir -p $PMABUILD_DIR
cd $PMABUILD_DIR
cmake -DCMAKE_BUILD_TYPE="Release" -DTWITTERVIS=OFF -DRHO_INIT=OFF ../pma_cd
make 

# make twitterVis
mkdir -p $BUILDIR
cd $BUILDIR 
cmake -DPMA_BUILD_DIR=$PMABUILD_DIR -DCMAKE_BUILD_TYPE="Release" ..
make

#get machine configuration
echo "" > $DATADIR/info.org
~/Projects/pmq/scripts/g5k_get_info.sh $DATADIR/info.org 

# EXECUTE BENCHMARK

#Continue execution even if one these fails
set +e 

#Run queries
#t=$((10**6))
t=26000
b=1000
#n=$(($t*$b))
ref=8
stdbuf -oL ./benchmarks/bench_queries_region -seed 123 -x 10 -rate ${b} -min_t ${t} -max_t ${t} -ref ${ref} -bf ../data/queriesLHS.csv >  ${TMPDIR}/bench_queries_region_random_${t}_${b}_${ref}_${EXECID}.log

set -e

cd $TMPDIR
tar -cvzf log_$EXECID.tgz *_$EXECID.log

cd $DATADIR
cp $TMPDIR/log_$EXECID.tgz .

git checkout $expId

git add info.org log_$EXECID.tgz run.sh 
git add -u
git commit -m "Finish execution $EXECID"
git push origin $expId
#+end_src 


** DONE Commit local changes
#+begin_src sh :results output :exports both
git status .
#+end_src

#+RESULTS:
#+begin_example
On branch exp20170915143003
Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git checkout -- <file>..." to discard changes in working directory)

	modified:   exp.org

Untracked files:
  (use "git add <file>..." to include in what will be committed)

	.#exp.org
	parse.sh
	plotResults.R
	run.sh

no changes added to commit (use "git add" and/or "git commit -a")
#+end_example

#+begin_src sh :results output :exports both
git add run.sh exp.org
git commit -m "UPD: run.sh script"
#git commit --amend -m "UPD: run.sh script"
#+end_src

#+RESULTS:
: [exp20170915143003 33c9084] UPD: run.sh script
:  2 files changed, 90 insertions(+), 18 deletions(-)
:  create mode 100755 data/cicero/exp20170915143003/run.sh

Push to remote
#+begin_src sh :results output :exports both :var expId=expId
#git push bitbucket $expId
git push origin $expId
#+end_src

#+RESULTS:

** CANCELED Local Execution                                          :local:
:LOGBOOK:
- State "CANCELED"   from "TODO"       [2017-09-05 Ter 19:00]
:END:

#+begin_src sh :results output :exports both :session local :var expId=expId
cd ~/Projects/pmq/data/$(hostname)/$expId
runid=$(date +%s)
tmux new -d -s runExp "cd ~/Projects/pmq/data/$(hostname)/$expId; ./run.sh ${runid} &> run_${runid}"
git add run_$runid
echo $runid
#+end_src

Check process running
#+begin_src sh :results output :exports both :session remote
tmux ls
ps ux
#+end_src

** TODO Remote Execution                                            :remote:

*** Get new changes on remote                                      :remote:
#+begin_src sh :session remote :results output :exports both 
ssh -A cicero
#+end_src

#+RESULTS:
#+begin_example

Welcome to Ubuntu 16.04.3 LTS (GNU/Linux 4.4.0-92-generic x86_64)

 ,* Documentation:  https://help.ubuntu.com
 ,* Management:     https://landscape.canonical.com
 ,* Support:        https://ubuntu.com/advantage

44 packages can be updated.
4 updates are security updates.

,*** System restart required ***
Last login: Thu Sep 14 17:24:35 2017 from 143.54.13.218
#+end_example

Get the last script on the remote machine (require entering a password
for bitbucket)
#+begin_src sh :session remote :results output :exports both :var expId=expId
cd ~/Projects/pmq/
git config --add remote.origin.fetch refs/heads/$expId:refs/remotes/origin/$expId
git fetch origin $expId
git checkout $expId
git pull origin $expId
git log -1 | cat 
#+end_src

#+RESULTS:
#+begin_example

julio@cicero:~/Projects/pmq$ julio@cicero:~/Projects/pmq$ remote: Counting objects: 13, done.
(1/10)           remote: Compressing objects:  20% (2/10)           remote: Compressing objects:  30% (3/10)           remote: Compressing objects:  40% (4/10)           remote: Compressing objects:  50% (5/10)           remote: Compressing objects:  60% (6/10)           remote: Compressing objects:  70% (7/10)           remote: Compressing objects:  80% (8/10)           remote: Compressing objects:  90% (9/10)           remote: Compressing objects: 100% (10/10)           remote: Compressing objects: 100% (10/10), done.        
remote: Total 13 (delta 6), reused 0 (delta 0)
(1/13)   Unpacking objects:  15% (2/13)   Unpacking objects:  23% (3/13)   Unpacking objects:  30% (4/13)   Unpacking objects:  38% (5/13)   Unpacking objects:  46% (6/13)   Unpacking objects:  53% (7/13)   Unpacking objects:  61% (8/13)   Unpacking objects:  69% (9/13)   Unpacking objects:  76% (10/13)   Unpacking objects:  84% (11/13)   Unpacking objects:  92% (12/13)   Unpacking objects: 100% (13/13)   Unpacking objects: 100% (13/13), done.
From bitbucket.org:jtoss/pmq
FETCH_HEAD
origin/exp20170915143003
Branch exp20170915143003 set up to track remote branch exp20170915143003 from origin.
Switched to a new branch 'exp20170915143003'
From bitbucket.org:jtoss/pmq
FETCH_HEAD
Already up-to-date.
commit 33c9084e53b9bd302e928ff9226e970e7086ac4f
Date:   Fri Sep 15 14:40:11 2017 -0300

    UPD: run.sh script
#+end_example

Update PMA repository on exp machine
#+begin_src sh :session remote :results output :exports both :var expId=expId
cd ~/Projects/hppsimulations/
git pull origin PMA_2016
git log -1 | cat
#+end_src

#+RESULTS:
: 
: julio@cicero:~/Projects/hppsimulations$ From bitbucket.org:joaocomba/pma
: FETCH_HEAD
: Already up-to-date.
: commit 011775f5fdeaeeff330da7df39751d9c5323b570
: Date:   Mon Feb 13 12:20:46 2017 -0200
: 
:     Bugfix: corrected pointer casts

*** DONE Execute Remotely                                          :remote:

Opens ssh connection and a tmux session

#+begin_src sh :results output :exports both :session remote :var expId=expId
cd ~/Projects/pmq/data/cicero/$expId
runid=$(date +%s)
tmux new -d -s runExp "cd ~/Projects/pmq/data/cicero/$expId; ./run.sh ${runid} &> run_${runid}"
git add run_$runid
echo $runid
#+end_src

#+RESULTS:
: 
: julio@cicero:~/Projects/pmq/data/cicero/exp20170915143003$ julio@cicero:~/Projects/pmq/data/cicero/exp20170915143003$ julio@cicero:~/Projects/pmq/data/cicero/exp20170915143003$ julio@cicero:~/Projects/pmq/data/cicero/exp20170915143003$ 1505503014

Check process running
#+begin_src sh :results output :exports both :session remote
tmux ls
ps ux
#+end_src

#+RESULTS:
#+begin_example
runExp: 1 windows (created Fri Sep 15 16:16:54 2017) [80x23]
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
julio    24661  0.0  0.0  45248  4608 ?        Ss   14:39   0:00 /lib/systemd/sy
julio    24663  0.0  0.0 145364  2112 ?        S    14:39   0:00 (sd-pam)
julio    24713  0.0  0.0  97464  3332 ?        D    14:39   0:00 sshd: julio@pts
julio    24714  0.0  0.0  22688  5180 pts/8    Ss   14:39   0:00 -bash
julio    25332  0.0  0.0  29420  2904 ?        Ss   16:16   0:00 tmux new -d -s 
julio    25333  0.0  0.0  12532  3020 pts/9    Ss+  16:16   0:00 bash -c cd ~/Pr
julio    25335  0.0  0.0  12544  3024 pts/9    S+   16:16   0:00 /bin/bash ./run
julio    25561 87.6  0.9 542264 306924 pts/9   R+   16:16   0:02 ./benchmarks/be
julio    25563  0.0  0.0  37368  3316 pts/8    R+   16:16   0:00 ps ux
#+end_example

**** DONE Pull local 
#+begin_src sh :results output :exports both :var expId=expId
#git commit -a -m "wip"
git status
git pull origin $expId
#+end_src

#+RESULTS:
#+begin_example
On branch exp20170915143003
Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git checkout -- <file>..." to discard changes in working directory)

	modified:   ../../../LabBook.org
	modified:   exp.org

Untracked files:
  (use "git add <file>..." to include in what will be committed)

	../../../LabBook.org.bkp
	../../../LabBook.org.orig
	../../../benchmarks/bench_insert_remove_count.cpp.orig
	../exp20170830124159/
	../exp20170904152622/
	../exp20170904153555/
	../exp20170914091842/
	.#exp.org
	bench_queries_region_random_26000_1000_8_1505497224.csv
	bench_queries_region_random_26000_1000_8_1505497224.log
	img/
	parse.sh
	plotResults.R
	../../../include/types.h.orig

no changes added to commit (use "git add" and/or "git commit -a")
Updating c084370..05add9e
Fast-forward
 data/cicero/exp20170915143003/info.org           |  76 +++++++++++------------
 data/cicero/exp20170915143003/log_1505503014.tgz | Bin 0 -> 38556 bytes
 data/cicero/exp20170915143003/run.sh             |   2 +-
 data/cicero/exp20170915143003/run_1505497224     |  11 ++++
 data/cicero/exp20170915143003/run_1505503014     |  44 +++++++++++++
 5 files changed, 94 insertions(+), 39 deletions(-)
 create mode 100644 data/cicero/exp20170915143003/log_1505503014.tgz
 create mode 100644 data/cicero/exp20170915143003/run_1505503014
#+end_example


* DONE Analysis
** DONE Generate csv files
:PROPERTIES: 
:HEADER-ARGS:sh: :tangle parse.sh :shebang #!/bin/bash
:END:      

List logFiles
#+begin_src sh :results table :exports both
ls -htl *tgz
#+end_src

#+RESULTS:
| -rw-rw-r-- | 1 | julio | julio | 16K | Set | 16 | 11:58 | log_1505497224.tgz |
| -rw-rw-r-- | 1 | julio | julio | 38K | Set | 16 | 11:58 | log_1505503014.tgz |

#+NAME: logFile
#+begin_src sh :results output :exports both 
tar xvzf log_1505503014.tgz
#+end_src

#+RESULTS: logFile
: bench_queries_region_random_26000_1000_8_1505503014.log

Create CSV using logFile 
#+begin_src sh :results output :exports both :var logFile=logFile[0]
#echo $logFile
echo $(basename -s .log $logFile ).csv
grep "; query ;" $logFile | sed "s/QueryBench//g" >  $(basename -s .log $logFile ).csv
#+end_src

#+NAME: csvFile
#+RESULTS:
: bench_queries_region_random_26000_1000_8_1505503014.csv

Create an director for images
#+begin_src sh :results output :exports both :tangle no
mkdir img
#+end_src

#+RESULTS:

** Results
:PROPERTIES: 
:HEADER-ARGS:R: :session *R* :tangle plotResults.R :shebang #!/usr/bin/env Rscript
:END:      
*** Prepare
Load the CSV into R
#+begin_src R :results output :exports both :var f=csvFile
library(tidyverse)

df <- f %>% read_delim(delim=";",trim_ws = TRUE, col_names = paste("V",c(1:11),sep="") )
df
#+end_src

#+RESULTS:
#+begin_example
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_logical(),
  V5 = col_integer(),
  V6 = col_character(),
  V7 = col_double(),
  V8 = col_character(),
  V9 = col_integer(),
  V10 = col_character(),
  V11 = col_integer()
)
Warning: 6400 parsing failures.
row # A tibble: 5 x 5 col     row   col   expected     actual expected   <int> <chr>      <chr>      <chr> actual 1     1  <NA> 11 columns 10 columns file 2     2  <NA> 11 columns 10 columns row 3     3  <NA> 11 columns 10 columns col 4     4  <NA> 11 columns 10 columns expected 5     5  <NA> 11 columns 10 columns actual # ... with 1 more variables: file <chr>
... ................. ... ................................... ........ ................................... ...... ................................... .... ................................... ... ................................... ... ................................... ........ ................................... ...... .......................................
See problems(...) for more details.

Warning message:
In rbind(names(probs), probs_f) :
  number of columns of result is not a multiple of vector length (arg 1)
# A tibble: 6,400 x 11
              V1    V2    V3    V4    V5             V6      V7
           <chr> <chr> <int> <lgl> <int>          <chr>   <dbl>
 1 GeoHashBinary query     0  TRUE 26000 scan_at_region 18.6587
 2 GeoHashBinary query     0  TRUE 26000 scan_at_region 18.7821
 3 GeoHashBinary query     0  TRUE 26000 scan_at_region 18.6673
 4 GeoHashBinary query     0  TRUE 26000 scan_at_region 18.6728
 5 GeoHashBinary query     0  TRUE 26000 scan_at_region 18.6935
 6 GeoHashBinary query     0  TRUE 26000 scan_at_region 18.7203
 7 GeoHashBinary query     0  TRUE 26000 scan_at_region 18.6842
 8 GeoHashBinary query     0  TRUE 26000 scan_at_region 18.6659
 9 GeoHashBinary query     0  TRUE 26000 scan_at_region 18.6754
10 GeoHashBinary query     0  TRUE 26000 scan_at_region 18.6662
# ... with 6,390 more rows, and 4 more variables: V8 <chr>, V9 <int>,
#   V10 <chr>, V11 <int>
#+end_example

Remove useless columns
#+begin_src R :results output :exports both :session 
names(df) <- c("algo" , "V2" , "queryId", "V4", "V5", "bench" , "ms" , "V8", "Refine","V10","Count")

df <- select(df, -V2, -V4, -V5, -V8, -V10)
df
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 6,400 x 6
            algo queryId          bench      ms Refine Count
           <chr>   <int>          <chr>   <dbl>  <int> <int>
 1 GeoHashBinary       0 scan_at_region 18.6587    482    NA
 2 GeoHashBinary       0 scan_at_region 18.7821    482    NA
 3 GeoHashBinary       0 scan_at_region 18.6673    482    NA
 4 GeoHashBinary       0 scan_at_region 18.6728    482    NA
 5 GeoHashBinary       0 scan_at_region 18.6935    482    NA
 6 GeoHashBinary       0 scan_at_region 18.7203    482    NA
 7 GeoHashBinary       0 scan_at_region 18.6842    482    NA
 8 GeoHashBinary       0 scan_at_region 18.6659    482    NA
 9 GeoHashBinary       0 scan_at_region 18.6754    482    NA
10 GeoHashBinary       0 scan_at_region 18.6662    482    NA
# ... with 6,390 more rows
#+end_example


Summary of the data frame
#+begin_src R :results output :session :exports both
summary(df[df$algo=="GeoHashBinary",])
summary(df[df$algo=="BTree",])
summary(df[df$algo=="RTree",])
#+end_src

#+RESULTS:
#+begin_example
     algo              queryId         bench                 ms           
 Length:1600        Min.   : 0.00   Length:1600        Min.   : 0.002588  
 Class :character   1st Qu.:19.75   Class :character   1st Qu.: 0.027660  
 Mode  :character   Median :39.50   Mode  :character   Median : 0.144764  
                    Mean   :39.50                      Mean   : 1.919891  
                    3rd Qu.:59.25                      3rd Qu.: 1.354142  
                    Max.   :79.00                      Max.   :19.097100  
                                                                          
     Refine          Count        
 Min.   :  1.0   Min.   :    184  
 1st Qu.:  9.0   1st Qu.:   2702  
 Median : 51.0   Median :  33371  
 Mean   :143.4   Mean   : 573496  
 3rd Qu.:189.0   3rd Qu.: 376592  
 Max.   :744.0   Max.   :3443858  
                 NA's   :800
     algo              queryId         bench                 ms          
 Length:1600        Min.   : 0.00   Length:1600        Min.   : 0.00219  
 Class :character   1st Qu.:19.75   Class :character   1st Qu.: 0.03647  
 Mode  :character   Median :39.50   Mode  :character   Median : 0.38434  
                    Mean   :39.50                      Mean   :10.02570  
                    3rd Qu.:59.25                      3rd Qu.: 7.28446  
                    Max.   :79.00                      Max.   :70.42940  
                                                                         
     Refine          Count        
 Min.   :  1.0   Min.   :    184  
 1st Qu.:  9.0   1st Qu.:   2702  
 Median : 51.0   Median :  33371  
 Mean   :143.4   Mean   : 573496  
 3rd Qu.:189.0   3rd Qu.: 376592  
 Max.   :744.0   Max.   :3443858  
                 NA's   :800
     algo              queryId         bench                 ms          
 Length:1600        Min.   : 0.00   Length:1600        Min.   : 0.00093  
 Class :character   1st Qu.:19.75   Class :character   1st Qu.: 0.02808  
 Mode  :character   Median :39.50   Mode  :character   Median : 0.29411  
                    Mean   :39.50                      Mean   :12.06190  
                    3rd Qu.:59.25                      3rd Qu.: 7.73104  
                    Max.   :79.00                      Max.   :96.55800  
                                                                         
     Refine            Count     
 Min.   :    184   Min.   : NA   
 1st Qu.:   2702   1st Qu.: NA   
 Median :  33371   Median : NA   
 Mean   : 573496   Mean   :NaN   
 3rd Qu.: 376592   3rd Qu.: NA   
 Max.   :3443858   Max.   : NA   
 NA's   :800       NA's   :1600
#+end_example

Summarize the averages
#+begin_src R :results output :session :exports both
dfplot <- 
    df %>% 
    group_by_at(vars(-ms)) %>%   #group_by all expect ms
    summarize(avg_ms = mean(ms), stdv = sd(ms)) %>%
    ungroup %>% 
    mutate(Count = if_else(bench=="apply_at_region" & is.na(Count) , Refine, Count), # fix the count an Refine columns for Rtrees
           Refine = ifelse(grepl("RTree",algo), NA, Refine))

dfplot %>% filter(queryId == 20)
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 8 x 7
           algo queryId           bench Refine  Count    avg_ms       stdv
          <chr>   <int>           <chr>  <int>  <int>     <dbl>      <dbl>
1         BTree      20 apply_at_region    108 214775 2.6816880 0.22956214
2         BTree      20  scan_at_region    108     NA 4.8140650 0.07039210
3 GeoHashBinary      20 apply_at_region    108 214775 0.4694510 0.09968918
4 GeoHashBinary      20  scan_at_region    108     NA 1.4375940 0.01467585
5         RTree      20 apply_at_region     NA 214776 3.3167700 0.29691903
6         RTree      20  scan_at_region     NA     NA 6.3906740 0.02903651
7     RTreeBulk      20 apply_at_region     NA 214776 0.5004929 0.01524547
8     RTreeBulk      20  scan_at_region     NA     NA 2.7961820 0.02158188
#+end_example

#+begin_src R :results output :exports both :session 
dfplot %>% filter(queryId == 10, bench == "scan_at_region", algo=="BTree") 
#+end_src

#+RESULTS:
: # A tibble: 1 x 7
:    algo queryId          bench Refine Count   avg_ms       stdv
:   <chr>   <int>          <chr>  <int> <int>    <dbl>      <dbl>
: 1 BTree      10 scan_at_region    255    NA 17.79931 0.09214822

*** Plot overview                                                  :export:
#+begin_src R :results output graphics :file "./img/overview_query_region.png" :exports results :width 800 :height 600 :session 

myplot <- function(data) {
    data %>%
#    filter( algo == "GeoHashBinary" ) %>%    
    #mutate(queryW = queryId %/% 10) %>%
    mutate(`Query Width` = 90 / 2**(queryId %/% 10)) %>%
#    arrange(desc(queryW)) %>%
    ggplot(aes(x = as.factor(queryId), y = avg_ms, color = algo)) +  
    geom_errorbar(aes(ymin = avg_ms - stdv, ymax = avg_ms + stdv) ) +
    geom_point() +
    #labs(title= data$bench) +     
#    scale_x_continuous(breaks=seq(0, 14, by=1)) +
    facet_wrap(bench~`Query Width`,scale="free", labeller = labeller(bench=c(apply_at_region="Count Query", scan_at_region="Scan Query"), `Query Width`=label_both)) + 
#    facet_wrap(~queryW,scale="free", labeller = "label_both") + 
#    facet_grid(queryW~bench,scale="free") + 
    theme(legend.position = "bottom",)
}
#dfplot %>% filter(bench == "scan_at_region") %>% myplot()
#dfplot %>% filter(bench == "apply_at_region") %>% myplot()
dfplot %>% 
    myplot() 
#+end_src

#+RESULTS:
[[file:./img/overview_query_region.png]]

*** Conclusions                                                    :export:

- PMQ shows its best benefits on large range queries.
- For small queries we are similar to othe Btree an Rtree.
- Bulk loading on Rtree only work on static case. The partitionning is optimized when all the queries are loaded together.


*NOTE* that in this synthetic dataset, the size of the query (in degrees) is proportional to the amount of elements returned because elements are uniformly distributed on the space. 
In a scenario of a Twitter distribution for instance, small queries will possibly result in very large amount of elements. 
We should expect a very different performance behavior in that cases.

** What is the actual count of elements per query ?


*** Table                                                          :export:

Variance shows that some counts differ between algorithms:
#+begin_src R :results output :exports none :session :colnames yes

dfplot %>% 
    filter( bench== "apply_at_region") %>% 
    group_by(queryId) %>%                     #group to see if every algo has same coubts
    summarize(Var = round(var(Count),3)  ) -> 
    countVariation

options(dplyr.width = Inf)
dfplot %>% 
    filter( bench == "apply_at_region") %>%
    ungroup( bench) %>% # must ungroup to drop the column
    select( -bench, -stdv, -Refine) %>%
    gather(measure, value, Count, avg_ms) %>%
    unite(temp, algo, measure) %>%
    spread( temp, value) %>% 
    #select(queryId,ends_with("Count") , ends_with("ms")) %>%
    select(queryId,ends_with("Count") ) %>%
 #   filter( !(BTree_Count == GeoHashBinary_Count & RTreeBulk_Count == RTree_Count & BTree_Count == RTree_Count)) %>% 
    inner_join(countVariation) -> wideTable

#+end_src

#+RESULTS:
: Joining, by = "queryId"

#+CAPTION: Number of elements returned in each query
#+begin_src R :results table :exports results :session :colnames yes
wideTable %>%
    as_tibble() %>%
    print(n = nrow(.))
#+end_src

#+RESULTS:
| queryId | BTree_Count | GeoHashBinary_Count | RTreeBulk_Count | RTree_Count |   Var |
|---------+-------------+---------------------+-----------------+-------------+-------|
|       0 |     3440580 |             3440580 |         3440580 |     3440580 |     0 |
|       1 |     3440446 |             3440446 |         3440447 |     3440447 | 0.333 |
|       2 |     3438884 |             3438884 |         3438884 |     3438884 |     0 |
|       3 |     3440915 |             3440915 |         3440916 |     3440916 | 0.333 |
|       4 |     3442356 |             3442356 |         3442356 |     3442356 |     0 |
|       5 |     3439224 |             3439224 |         3439224 |     3439224 |     0 |
|       6 |     3438953 |             3438953 |         3438953 |     3438953 |     0 |
|       7 |     3442233 |             3442233 |         3442234 |     3442234 | 0.333 |
|       8 |     3441859 |             3441859 |         3441859 |     3441859 |     0 |
|       9 |     3443858 |             3443858 |         3443858 |     3443858 |     0 |
|      10 |      859819 |              859819 |          859819 |      859819 |     0 |
|      11 |      860304 |              860304 |          860304 |      860304 |     0 |
|      12 |      862004 |              862004 |          862004 |      862004 |     0 |
|      13 |      859895 |              859895 |          859895 |      859895 |     0 |
|      14 |      862262 |              862262 |          862263 |      862263 | 0.333 |
|      15 |      859189 |              859189 |          859189 |      859189 |     0 |
|      16 |      859264 |              859264 |          859266 |      859266 | 1.333 |
|      17 |      861935 |              861935 |          861935 |      861935 |     0 |
|      18 |      861341 |              861341 |          861341 |      861341 |     0 |
|      19 |      859799 |              859799 |          859799 |      859799 |     0 |
|      20 |      214775 |              214775 |          214776 |      214776 | 0.333 |
|      21 |      214220 |              214220 |          214220 |      214220 |     0 |
|      22 |      215543 |              215543 |          215543 |      215543 |     0 |
|      23 |      214932 |              214932 |          214932 |      214932 |     0 |
|      24 |      215726 |              215726 |          215726 |      215726 |     0 |
|      25 |      214526 |              214526 |          214526 |      214526 |     0 |
|      26 |      215502 |              215502 |          215502 |      215502 |     0 |
|      27 |      214199 |              214199 |          214199 |      214199 |     0 |
|      28 |      215471 |              215471 |          215471 |      215471 |     0 |
|      29 |      214738 |              214738 |          214738 |      214738 |     0 |
|      30 |       53488 |               53488 |           53488 |       53488 |     0 |
|      31 |       54129 |               54129 |           54129 |       54129 |     0 |
|      32 |       53212 |               53212 |           53212 |       53212 |     0 |
|      33 |       53584 |               53584 |           53584 |       53584 |     0 |
|      34 |       53724 |               53724 |           53724 |       53724 |     0 |
|      35 |       53825 |               53825 |           53825 |       53825 |     0 |
|      36 |       53856 |               53856 |           53856 |       53856 |     0 |
|      37 |       53236 |               53236 |           53236 |       53236 |     0 |
|      38 |       53837 |               53837 |           53837 |       53837 |     0 |
|      39 |       53767 |               53767 |           53767 |       53767 |     0 |
|      40 |       13230 |               13230 |           13230 |       13230 |     0 |
|      41 |       13399 |               13399 |           13400 |       13400 | 0.333 |
|      42 |       13513 |               13513 |           13514 |       13514 | 0.333 |
|      43 |       13251 |               13251 |           13251 |       13251 |     0 |
|      44 |       13524 |               13524 |           13524 |       13524 |     0 |
|      45 |       13356 |               13356 |           13356 |       13356 |     0 |
|      46 |       13401 |               13401 |           13401 |       13401 |     0 |
|      47 |       13530 |               13530 |           13530 |       13530 |     0 |
|      48 |       13417 |               13417 |           13417 |       13417 |     0 |
|      49 |       13298 |               13298 |           13298 |       13298 |     0 |
|      50 |        3358 |                3358 |            3358 |        3358 |     0 |
|      51 |        3304 |                3304 |            3304 |        3304 |     0 |
|      52 |        3517 |                3517 |            3517 |        3517 |     0 |
|      53 |        3338 |                3338 |            3338 |        3338 |     0 |
|      54 |        3394 |                3394 |            3394 |        3394 |     0 |
|      55 |        3353 |                3353 |            3353 |        3353 |     0 |
|      56 |        3356 |                3356 |            3357 |        3357 | 0.333 |
|      57 |        3440 |                3440 |            3440 |        3440 |     0 |
|      58 |        3455 |                3455 |            3455 |        3455 |     0 |
|      59 |        3461 |                3461 |            3461 |        3461 |     0 |
|      60 |         842 |                 842 |             842 |         842 |     0 |
|      61 |         808 |                 808 |             808 |         808 |     0 |
|      62 |         840 |                 840 |             840 |         840 |     0 |
|      63 |         834 |                 834 |             834 |         834 |     0 |
|      64 |         839 |                 839 |             839 |         839 |     0 |
|      65 |         852 |                 852 |             852 |         852 |     0 |
|      66 |         797 |                 797 |             797 |         797 |     0 |
|      67 |         843 |                 843 |             843 |         843 |     0 |
|      68 |         813 |                 813 |             813 |         813 |     0 |
|      69 |         895 |                 895 |             895 |         895 |     0 |
|      70 |         225 |                 225 |             225 |         225 |     0 |
|      71 |         184 |                 184 |             184 |         184 |     0 |
|      72 |         209 |                 209 |             209 |         209 |     0 |
|      73 |         199 |                 199 |             199 |         199 |     0 |
|      74 |         212 |                 212 |             212 |         212 |     0 |
|      75 |         222 |                 222 |             222 |         222 |     0 |
|      76 |         213 |                 213 |             213 |         213 |     0 |
|      77 |         192 |                 192 |             192 |         192 |     0 |
|      78 |         196 |                 196 |             196 |         196 |     0 |
|      79 |         188 |                 188 |             188 |         188 |     0 |
#+TBLFM: $6=$0;%0.3f



Just the diverging queries : 
#+begin_src R :results table :exports results :session :colnames yes

wideTable %>%
    filter ( Var > 0) %>%            #get only the queryIds with variance greater that zero 
    as_tibble() %>%
    print(n = nrow(.))

#+end_src

#+CAPTION: Queries that returned different result depending on the algorithm 
#+RESULTS:
| queryId | BTree_Count | GeoHashBinary_Count | RTreeBulk_Count | RTree_Count |   Var |
|---------+-------------+---------------------+-----------------+-------------+-------|
|       1 |     3440446 |             3440446 |         3440447 |     3440447 | 0.333 |
|       3 |     3440915 |             3440915 |         3440916 |     3440916 | 0.333 |
|       7 |     3442233 |             3442233 |         3442234 |     3442234 | 0.333 |
|      14 |      862262 |              862262 |          862263 |      862263 | 0.333 |
|      16 |      859264 |              859264 |          859266 |      859266 | 1.333 |
|      20 |      214775 |              214775 |          214776 |      214776 | 0.333 |
|      41 |       13399 |               13399 |           13400 |       13400 | 0.333 |
|      42 |       13513 |               13513 |           13514 |       13514 | 0.333 |
|      56 |        3356 |                3356 |            3357 |        3357 | 0.333 |


*** Plot                                                           :export:

There are some queries where the count differs for Rtree by a small amount of elements.

Counts have some differences :
#+begin_src R :results output :exports none :session 
options(dplyr.width = Inf)
dfplot %>% 
    filter( bench== "apply_at_region") %>% 
    group_by(queryId, bench) %>% #group to see if every algo has same counts
    summarize(c = mean(Count), s = sd(Count)  ) %>% 
    filter ( s > 0) %>% 
    select(queryId, bench) %>% 
    left_join(dfplot) -> dfWrongCounts

#+end_src

#+RESULTS:
: Joining, by = c("queryId", "bench")


These are the queries that for some misterious reason resulted in different counts.
#+begin_src R :results output graphics :file "./img/differing_counts.png" :exports results :width 600 :height 400 :session 

myplot <- function(data) {
    data %>%
   #     mutate(`Query Width` = 90 / 2**(queryId %/% 10)) %>%
        ggplot(aes(x = as.factor(algo), y = Count, color = algo))+
# as.numeric(labels(as.factor(unique(algo))))), y = Count, color = algo)) +  
        #geom_jitter( width=0.1, height=0) +
        geom_point( ) +
        facet_wrap(~queryId,scale="free", labeller = "label_both") + 
        theme(legend.position = "bottom",) + 
#        labs(x = "Query width (degrees)") +
        #scale_y_continuous(breaks=c(3440446,3440447) )
        scale_y_continuous(breaks=seq(min(data$Count),max(data$Count) ))
    
}

#dfWrongCounts %>% myplot() 

dfWrongCounts %>% myplot()

#dfWrongCounts %>% 
#group_by(queryId) %>% filter(queryId == 1 ) %>%
#mutate(y_min = min(Count), y_max = max(Count)) %>% myplot()
#+end_src

#+RESULTS:
[[file:./img/differing_counts.png]]

