# -*- org-export-babel-evaluate: t; -*-
#+TITLE: Benchmark Queries - Twitter Dataset
#+LANGUAGE: en 
#+STARTUP: indent
#+STARTUP: logdrawer hideblocks
#+SEQ_TODO: TODO INPROGRESS(i) | DONE DEFERRED(@) CANCELED(@)
#+TAGS: @JULIO(J)
#+TAGS: IMPORTANT(i) TEST(t) DEPRECATED(d) noexport(n) ignore(n) export(e)
#+CATEGORY: exp
#+OPTIONS: ^:{} todo:nil H:4 toc:t tags:nil author:nil
#+PROPERTY: header-args :cache no :eval never-export 


* TODO Description                                                   :export:

Test to check better refinemnet levels. 

- PMQ / GEOHASH
- BTREE 
  
- test with twitter dataset


- Total elements = T * 1000  
  
Use the synthetic queries generated by the DoE in [[file:~/Projects/pmq/data/queriesLHS.org::#queries20170923145357][Twitter Data]].

queries Dataset : [[file:~/Projects/pmq/data/queriesTwitter.csv]]

** Standalone script                                              :noexport:
To generate the results outside emacs and orgmode you can use the standalone scripts, generated from the tangled source blocks in this file

- parse.sh : parse the results to CSV
- plotResults.R : generate the plots 
  

* TODO Experiment Script
** DONE Initial Setup 

#+begin_src sh :results value :exports both
expId=$(basename $(pwd))
echo $expId
#+end_src

#+NAME: expId
#+RESULTS:
: exp20171111161232

Set up git branch
#+begin_src sh :results output :exports both :var expId=expId
git checkout master
git commit ../../../LabBook.org -m "LBK: new entry for ${expId}"
#+end_src

#+RESULTS:
: M	LabBook.org
: Your branch is ahead of 'origin/master' by 2 commits.
:   (use "git push" to publish your local commits)
: [master bd2ed0d] LBK: new entry for exp20171111161232
:  1 file changed, 35 insertions(+)

Create EXP branch
#+begin_src sh :results output :exports both :var expId=expId
git checkout -b $expId
#+end_src

#+RESULTS:

Commit branch
#+begin_src sh :results output :exports both :var expId=expId
git status .
git add exp.org
git commit -m "Initial commit for $expId"
#+end_src

#+RESULTS:
#+begin_example
On branch exp20171111161232
Untracked files:
  (use "git add <file>..." to include in what will be committed)

	.#exp.org
	exp.org

nothing added to commit but untracked files present (use "git add" to track)
[exp20171111161232 d06e7c2] Initial commit for exp20171111161232
 1 file changed, 1068 insertions(+)
 create mode 100644 data/cicero/exp20171111161232/exp.org
#+end_example

#+begin_src sh :results output :exports both :var expId=expId
git la -3 
#+end_src

#+RESULTS:
: * d06e7c2 (HEAD -> exp20171111161232) Initial commit for exp20171111161232
: * bd2ed0d (master) LBK: new entry for exp20171111161232
: | * 8a4aa51 (temp) Replicate test with random tweets on my machine

** DONE Export run script 

- Test refinements levels on twitter dataset 

#+begin_src sh :results output :exports both

for I in 1 2 4 8 16 32 64 128 ; do
    T=$(($I * 1000))
    echo "$T"
done
#+end_src

#+RESULTS:
: 1000
: 2000
: 4000
: 8000
: 16000
: 32000
: 64000
: 128000

Use C-u C-c C-v t to tangle this script 
#+begin_src sh :results output :exports both :tangle run.sh :shebang #!/bin/bash :eval never :var expId=expId
set -e
# Any subsequent(*) commands which fail will cause the shell script to exit immediately
echo $(hostname) 

##########################################################
### SETUP THIS VARIABLES

BUILDIR=~/Projects/pmq/build-release
PMABUILD_DIR=~/Projects/hppsimulations/build-release
DATADIR=$(pwd)
# workaround as :var arguments are not been correctly tangled by my orgmode
#expId=$(basename $(pwd) | sed 's/exp//g')
expId=$(basename $(pwd))
TMPDIR=/dev/shm/$expId

# generate output name
if [ $1 ] ; then 
    EXECID=$1
else
    EXECID=$(date +%s)
fi

#########################################################

mkdir -p $TMPDIR
#mkdir -p $DATADIR

# make pma
mkdir -p $PMABUILD_DIR
cd $PMABUILD_DIR
cmake -DCMAKE_BUILD_TYPE="Release" -DTWITTERVIS=OFF -DRHO_INIT=OFF ../pma_cd
make 

# make twitterVis
mkdir -p $BUILDIR
cd $BUILDIR 
cmake -DPMA_BUILD_DIR=$PMABUILD_DIR -DELT_SIZE=0 -DCMAKE_BUILD_TYPE="Release" -DBENCH_PMQ=ON -DBENCH_BTREE=ON -DBENCH_RTREE=OFF -DBENCH_DENSE=OFF -DBENCH_RTREE_BULK=OFF ..
make

#get machine configuration
echo "" > $DATADIR/info.org
~/Projects/pmq/scripts/g5k_get_info.sh $DATADIR/info.org 

# EXECUTE BENCHMARK

#Continue execution even if one these fails
set +e 

#Run queries
b=1000
#n=$(($t*$b))
#ref=8

    
listRef=$(seq 1 14)
for ref in $listRef
    for i in 1 2 ; do
        t=$(($i * 1000))
        stdbuf -oL ./benchmarks/bench_queries_region -f ../data/geo-tweets.dat -x 10 -rate ${b} -min_t ${t} -max_t ${t} -ref ${ref} -bf ../data/queriesTwitter.csv >  ${TMPDIR}/bench_queries_region_twitter_${t}_${b}_${ref}_${EXECID}.log
    done
done

set -e

cd $TMPDIR
tar -cvzf log_$EXECID.tgz *_$EXECID.log

cd $DATADIR
cp $TMPDIR/log_$EXECID.tgz .

git checkout $expId

git add info.org log_$EXECID.tgz run.sh 
git add -u
git commit -m "Finish execution $EXECID"
#git push origin $expId
#+end_src 


** DONE Commit local changes
#+begin_src sh :results output :exports both
git status .
#+end_src

#+RESULTS:
#+begin_example
On branch exp20171111161232
Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git checkout -- <file>..." to discard changes in working directory)

	modified:   exp.org

Untracked files:
  (use "git add <file>..." to include in what will be committed)

	run.sh

no changes added to commit (use "git add" and/or "git commit -a")
#+end_example

#+begin_src sh :results output :exports both
git add run.sh exp.org
git commit -m "UPD: run.sh script"
#git commit --amend -m "UPD: run.sh script"
#+end_src

#+RESULTS:
: [exp20171111161232 ebb4318] UPD: run.sh script
:  2 files changed, 102 insertions(+), 21 deletions(-)
:  create mode 100755 data/cicero/exp20171111161232/run.sh

Push to remote (directly to the experiment machine)
#+begin_src sh :results output :exports both :var expId=expId
#git push bitbucket $expId
#git push origin $expId
git push cicero $expId
#+end_src

#+RESULTS:

** CANCELED Local Execution                                          :local:
:LOGBOOK:
- State "CANCELED"   from "TODO"       [2017-09-05 Ter 19:00]
:END:

#+begin_src sh :results output :exports both :session local :var expId=expId
cd ~/Projects/pmq/data/$(hostname)/$expId
runid=$(date +%s)
tmux new -d -s runExp "cd ~/Projects/pmq/data/$(hostname)/$expId; ./run.sh ${runid} &> run_${runid}"
git add run_$runid
echo $runid
#+end_src

Check process running
#+begin_src sh :results output :exports both :session remote
tmux ls
ps ux
#+end_src

** DONE Remote Execution                                            :remote:

*** Get new changes on remote                                      :remote:
#+begin_src sh :session remote :results output :exports both 
ssh -A cicero
#+end_src

#+RESULTS:
#+begin_example
julio@cicero's password: 
Welcome to Ubuntu 16.04.3 LTS (GNU/Linux 4.4.0-92-generic x86_64)

 ,* Documentation:  https://help.ubuntu.com
 ,* Management:     https://landscape.canonical.com
 ,* Support:        https://ubuntu.com/advantage

115 packages can be updated.
0 updates are security updates.

,*** System restart required ***
Last login: Sat Nov 11 16:21:42 2017 from 143.54.11.6
#+end_example

Get the last script on the remote machine (require entering a password
for bitbucket)
#+begin_src sh :session remote :results output :exports both :var expId=expId
cd ~/Projects/pmq/
#git config --add remote.origin.fetch refs/heads/$expId:refs/remotes/origin/$expId
#git fetch origin $expId
git checkout $expId
#git pull origin $expId
#git log -1 | cat 
#+end_src

#+RESULTS:
: 
: julio@cicero:~/Projects/pmq$ julio@cicero:~/Projects/pmq$ julio@cicero:~/Projects/pmq$ Switched to branch 'exp20171111161232'

Update PMA repository on exp machine
#+begin_src sh :session remote :results output :exports both :var expId=expId
cd ~/Projects/hppsimulations/
git pull origin PMA_2016
git log -1 | cat
#+end_src

#+RESULTS:
: 
: julio@cicero:~/Projects/hppsimulations$ From bitbucket.org:joaocomba/pma
: FETCH_HEAD
: Already up-to-date.
: commit 6931408d8b9c109f3f2a9543374cfd712791b1e7
: Date:   Tue Sep 19 16:58:38 2017 -0300
: 
:     error ouput on pma initialization

*** DONE Execute Remotely                                          :remote:

Opens ssh connection and a tmux session

#+begin_src sh :results output :exports both :session remote :var expId=expId
cd ~/Projects/pmq/data/cicero/$expId
runid=$(date +%s)
tmux new -d -s runExp "cd ~/Projects/pmq/data/cicero/$expId; ./run.sh ${runid} &> run_${runid}"
git add run_$runid
echo $runid
#+end_src

#+RESULTS:
: 
: julio@cicero:~/Projects/pmq/data/cicero/exp20171111161232$ julio@cicero:~/Projects/pmq/data/cicero/exp20171111161232$ julio@cicero:~/Projects/pmq/data/cicero/exp20171111161232$ julio@cicero:~/Projects/pmq/data/cicero/exp20171111161232$ 1510425176

Check process running
#+begin_src sh :results output :exports both :session remote
tmux ls
ps ux
#+end_src

#+RESULTS:
: no server running on /tmp/tmux-1001/default
: USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
: julio    16748  0.0  0.0  45248  4604 ?        Ss   16:21   0:00 /lib/systemd/systemd --user
: julio    16750  0.0  0.0 145352  2100 ?        S    16:21   0:00 (sd-pam)
: julio    16800  0.0  0.0  97576  3464 ?        S    16:21   0:00 sshd: julio@pts/8
: julio    16801  0.0  0.0  23724  6416 pts/8    Ss+  16:21   0:00 -bash
: julio    16995  0.0  0.0  97496  3348 ?        S    16:27   0:00 sshd: julio@pts/9
: julio    16996  0.0  0.0  22676  5112 pts/9    Ss   16:27   0:00 -bash
: julio    17676  0.0  0.0  37368  3248 pts/9    R+   16:50   0:00 ps ux

**** DONE Pull local 
#+begin_src sh :results output :exports both :var expId=expId
#git commit -a -m "wip"
#git status
#git pull --rebase origin $expId
git pull cicero $expId
#+end_src

#+RESULTS:
#+begin_example
[exp20171012184842 37984b2] wip
 1 file changed, 29 insertions(+), 26 deletions(-)
On branch exp20171012184842
Untracked files:
  (use "git add <file>..." to include in what will be committed)

	../../../LabBook.man
	../../../LabBook.markdown_phpextra
	../../../LabBook.md
	../../../LabBook.rst
	../../../LabBook.rtf
	../../../LabBook.txt
	../../../LabBook_BACKUP_19287.md
	../../../LabBook_BACKUP_19287.org
	../../../LabBook_BASE_19287.org
	../../../LabBook_LOCAL_19287.org
	../../../LabBook_REMOTE_19287.org
	../../../README.html
	../exp20170825181747/
	../exp20170830124159/
	../exp20170907105314/
	../exp20170907105804/
	../exp20170907112116/
	../exp20170907145711/
	../exp20170914091842/
	../exp20170915143003/
	../exp20170919161448/
	../exp20170923144931/
	../exp20170923193058/
	../exp20171009155025/
	exp.pdf
	exp.tex
	img/
	../../queriesLHS.html
	../../queriesLHS_BACKUP_23848.org
	../../queriesLHS_BASE_23848.org
	../../queriesLHS_LOCAL_23848.org
	../../queriesLHS_REMOTE_23848.org
	../../randomLhsQueries.png
	../../../history.txt
	../../../qqqq

nothing added to commit but untracked files present (use "git add" to track)
First, rewinding head to replay your work on top of it...
Applying: wip
#+end_example

* Refinement Level Analysis
** DONE Generate csv files
:PROPERTIES: 
:HEADER-ARGS:sh: :tangle parse.sh :shebang #!/bin/bash
:END:      

List logFiles
#+begin_src sh :results table :exports both
ls -htl *tgz
#+end_src

#+RESULTS:
| -rw-r--r-- 1 julio julio 669K nov 11 16:51 log_1510425176.tgz |

#+NAME: logFile
#+begin_src sh :results table :exports both 
tar xvzf log_*.tgz
#+end_src

#+RESULTS: logFile
| bench_queries_region_twitter_1000_1000_10_1510425176.log |
| bench_queries_region_twitter_1000_1000_11_1510425176.log |
| bench_queries_region_twitter_1000_1000_1_1510425176.log  |
| bench_queries_region_twitter_1000_1000_12_1510425176.log |
| bench_queries_region_twitter_1000_1000_13_1510425176.log |
| bench_queries_region_twitter_1000_1000_14_1510425176.log |
| bench_queries_region_twitter_1000_1000_2_1510425176.log  |
| bench_queries_region_twitter_1000_1000_3_1510425176.log  |
| bench_queries_region_twitter_1000_1000_4_1510425176.log  |
| bench_queries_region_twitter_1000_1000_5_1510425176.log  |
| bench_queries_region_twitter_1000_1000_6_1510425176.log  |
| bench_queries_region_twitter_1000_1000_7_1510425176.log  |
| bench_queries_region_twitter_1000_1000_8_1510425176.log  |
| bench_queries_region_twitter_1000_1000_9_1510425176.log  |
| bench_queries_region_twitter_2000_1000_10_1510425176.log |
| bench_queries_region_twitter_2000_1000_11_1510425176.log |
| bench_queries_region_twitter_2000_1000_1_1510425176.log  |
| bench_queries_region_twitter_2000_1000_12_1510425176.log |
| bench_queries_region_twitter_2000_1000_13_1510425176.log |
| bench_queries_region_twitter_2000_1000_14_1510425176.log |
| bench_queries_region_twitter_2000_1000_2_1510425176.log  |
| bench_queries_region_twitter_2000_1000_3_1510425176.log  |
| bench_queries_region_twitter_2000_1000_4_1510425176.log  |
| bench_queries_region_twitter_2000_1000_5_1510425176.log  |
| bench_queries_region_twitter_2000_1000_6_1510425176.log  |
| bench_queries_region_twitter_2000_1000_7_1510425176.log  |
| bench_queries_region_twitter_2000_1000_8_1510425176.log  |
| bench_queries_region_twitter_2000_1000_9_1510425176.log  |

Create CSV using logFile 

#+NAME: csvFile
#+begin_src sh :results output :exports both :var logFileList=logFile

#echo $logFile | sed 's/bench_queries_region_random_10000_100_\([[:digit:]]\)//g'
for logFile in $logFileList
do
echo $(basename -s .log $logFile ).csv
grep "GeoHashBinary\|BTree" $logFile | grep "query" | sed "s/QueryBench//g" >  $(basename -s .log $logFile ).csv
done

#+end_src

#+RESULTS: csvFile
#+begin_example
bench_queries_region_twitter_1000_1000_10_1510425176.csv
bench_queries_region_twitter_1000_1000_11_1510425176.csv
bench_queries_region_twitter_1000_1000_1_1510425176.csv
bench_queries_region_twitter_1000_1000_12_1510425176.csv
bench_queries_region_twitter_1000_1000_13_1510425176.csv
bench_queries_region_twitter_1000_1000_14_1510425176.csv
bench_queries_region_twitter_1000_1000_2_1510425176.csv
bench_queries_region_twitter_1000_1000_3_1510425176.csv
bench_queries_region_twitter_1000_1000_4_1510425176.csv
bench_queries_region_twitter_1000_1000_5_1510425176.csv
bench_queries_region_twitter_1000_1000_6_1510425176.csv
bench_queries_region_twitter_1000_1000_7_1510425176.csv
bench_queries_region_twitter_1000_1000_8_1510425176.csv
bench_queries_region_twitter_1000_1000_9_1510425176.csv
bench_queries_region_twitter_2000_1000_10_1510425176.csv
bench_queries_region_twitter_2000_1000_11_1510425176.csv
bench_queries_region_twitter_2000_1000_1_1510425176.csv
bench_queries_region_twitter_2000_1000_12_1510425176.csv
bench_queries_region_twitter_2000_1000_13_1510425176.csv
bench_queries_region_twitter_2000_1000_14_1510425176.csv
bench_queries_region_twitter_2000_1000_2_1510425176.csv
bench_queries_region_twitter_2000_1000_3_1510425176.csv
bench_queries_region_twitter_2000_1000_4_1510425176.csv
bench_queries_region_twitter_2000_1000_5_1510425176.csv
bench_queries_region_twitter_2000_1000_6_1510425176.csv
bench_queries_region_twitter_2000_1000_7_1510425176.csv
bench_queries_region_twitter_2000_1000_8_1510425176.csv
bench_queries_region_twitter_2000_1000_9_1510425176.csv
#+end_example


Create an director for images
#+begin_src sh :results output :exports both :tangle no
mkdir img
#+end_src

#+RESULTS:

** Results
:PROPERTIES: 
:HEADER-ARGS:R: :session *R* :tangle plotResults.R :shebang #!/usr/bin/env Rscript
:END:      


Load the CSV into R
#+begin_src R :results output :exports both :var f=csvFile path=(print default-directory)
setwd(path)
library(tidyverse)

                                        # Reads a csv file and add a column identifying the csv by parsin its name
readAdd <- function(input){

return ( read_delim(input,delim=";",trim_ws = TRUE, col_names = paste("V",c(1:11),sep="") ) %>%
         mutate (
             ref = as.factor(
                 gsub("bench_queries_region_twitter_[[:digit:]]+_1000_([[:digit:]]+)_.*","\\1",input))))
} 


files = strsplit(f,"\n")[[1]]

df <- files %>%
    map(readAdd) %>%   # use my custom read function
    reduce(rbind)   # used rbind to combine into one dataframe

#+end_src

#+RESULTS:
#+begin_example
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_logical(),
  V5 = col_integer(),
  V6 = col_character(),
  V7 = col_double(),
  V8 = col_character(),
  V9 = col_integer(),
  V10 = col_character(),
  V11 = col_integer()
)
Warning: 3200 parsing failures.
row # A tibble: 5 x 5 col     row   col   expected     actual                                                       file expected   <int> <chr>      <chr>      <chr>                                                      <chr> actual 1     1  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_10_1510425176.csv' file 2     2  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_10_1510425176.csv' row 3     3  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_10_1510425176.csv' col 4     4  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_10_1510425176.csv' expected 5     5  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_10_1510425176.csv'
... ................. ... .............................................................................................. ........ .............................................................................................. ...... ................ [... truncated]
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_logical(),
  V5 = col_integer(),
  V6 = col_character(),
  V7 = col_double(),
  V8 = col_character(),
  V9 = col_integer(),
  V10 = col_character(),
  V11 = col_integer()
)
Warning: 3200 parsing failures.
row # A tibble: 5 x 5 col     row   col   expected     actual                                                       file expected   <int> <chr>      <chr>      <chr>                                                      <chr> actual 1     1  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_11_1510425176.csv' file 2     2  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_11_1510425176.csv' row 3     3  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_11_1510425176.csv' col 4     4  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_11_1510425176.csv' expected 5     5  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_11_1510425176.csv'
... ................. ... .............................................................................................. ........ .............................................................................................. ...... ................ [... truncated]
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_logical(),
  V5 = col_integer(),
  V6 = col_character(),
  V7 = col_double(),
  V8 = col_character(),
  V9 = col_integer(),
  V10 = col_character(),
  V11 = col_integer()
)
Warning: 3200 parsing failures.
row # A tibble: 5 x 5 col     row   col   expected     actual                                                      file expected   <int> <chr>      <chr>      <chr>                                                     <chr> actual 1     1  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_1_1510425176.csv' file 2     2  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_1_1510425176.csv' row 3     3  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_1_1510425176.csv' col 4     4  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_1_1510425176.csv' expected 5     5  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_1_1510425176.csv'
... ................. ... ............................................................................................. ........ ............................................................................................. ...... ......................... [... truncated]
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_logical(),
  V5 = col_integer(),
  V6 = col_character(),
  V7 = col_double(),
  V8 = col_character(),
  V9 = col_integer(),
  V10 = col_character(),
  V11 = col_integer()
)
Warning: 3200 parsing failures.
row # A tibble: 5 x 5 col     row   col   expected     actual                                                       file expected   <int> <chr>      <chr>      <chr>                                                      <chr> actual 1     1  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_12_1510425176.csv' file 2     2  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_12_1510425176.csv' row 3     3  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_12_1510425176.csv' col 4     4  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_12_1510425176.csv' expected 5     5  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_12_1510425176.csv'
... ................. ... .............................................................................................. ........ .............................................................................................. ...... ................ [... truncated]
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_logical(),
  V5 = col_integer(),
  V6 = col_character(),
  V7 = col_double(),
  V8 = col_character(),
  V9 = col_integer(),
  V10 = col_character(),
  V11 = col_integer()
)
Warning: 3200 parsing failures.
row # A tibble: 5 x 5 col     row   col   expected     actual                                                       file expected   <int> <chr>      <chr>      <chr>                                                      <chr> actual 1     1  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_13_1510425176.csv' file 2     2  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_13_1510425176.csv' row 3     3  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_13_1510425176.csv' col 4     4  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_13_1510425176.csv' expected 5     5  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_13_1510425176.csv'
... ................. ... .............................................................................................. ........ .............................................................................................. ...... ................ [... truncated]
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_logical(),
  V5 = col_integer(),
  V6 = col_character(),
  V7 = col_double(),
  V8 = col_character(),
  V9 = col_integer(),
  V10 = col_character(),
  V11 = col_integer()
)
Warning: 3200 parsing failures.
row # A tibble: 5 x 5 col     row   col   expected     actual                                                       file expected   <int> <chr>      <chr>      <chr>                                                      <chr> actual 1     1  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_14_1510425176.csv' file 2     2  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_14_1510425176.csv' row 3     3  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_14_1510425176.csv' col 4     4  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_14_1510425176.csv' expected 5     5  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_14_1510425176.csv'
... ................. ... .............................................................................................. ........ .............................................................................................. ...... ................ [... truncated]
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_logical(),
  V5 = col_integer(),
  V6 = col_character(),
  V7 = col_double(),
  V8 = col_character(),
  V9 = col_integer(),
  V10 = col_character(),
  V11 = col_integer()
)
Warning: 3200 parsing failures.
row # A tibble: 5 x 5 col     row   col   expected     actual                                                      file expected   <int> <chr>      <chr>      <chr>                                                     <chr> actual 1     1  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_2_1510425176.csv' file 2     2  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_2_1510425176.csv' row 3     3  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_2_1510425176.csv' col 4     4  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_2_1510425176.csv' expected 5     5  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_2_1510425176.csv'
... ................. ... ............................................................................................. ........ ............................................................................................. ...... ......................... [... truncated]
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_logical(),
  V5 = col_integer(),
  V6 = col_character(),
  V7 = col_double(),
  V8 = col_character(),
  V9 = col_integer(),
  V10 = col_character(),
  V11 = col_integer()
)
Warning: 3200 parsing failures.
row # A tibble: 5 x 5 col     row   col   expected     actual                                                      file expected   <int> <chr>      <chr>      <chr>                                                     <chr> actual 1     1  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_3_1510425176.csv' file 2     2  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_3_1510425176.csv' row 3     3  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_3_1510425176.csv' col 4     4  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_3_1510425176.csv' expected 5     5  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_3_1510425176.csv'
... ................. ... ............................................................................................. ........ ............................................................................................. ...... ......................... [... truncated]
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_logical(),
  V5 = col_integer(),
  V6 = col_character(),
  V7 = col_double(),
  V8 = col_character(),
  V9 = col_integer(),
  V10 = col_character(),
  V11 = col_integer()
)
Warning: 3200 parsing failures.
row # A tibble: 5 x 5 col     row   col   expected     actual                                                      file expected   <int> <chr>      <chr>      <chr>                                                     <chr> actual 1     1  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_4_1510425176.csv' file 2     2  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_4_1510425176.csv' row 3     3  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_4_1510425176.csv' col 4     4  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_4_1510425176.csv' expected 5     5  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_4_1510425176.csv'
... ................. ... ............................................................................................. ........ ............................................................................................. ...... ......................... [... truncated]
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_logical(),
  V5 = col_integer(),
  V6 = col_character(),
  V7 = col_double(),
  V8 = col_character(),
  V9 = col_integer(),
  V10 = col_character(),
  V11 = col_integer()
)
Warning: 3200 parsing failures.
row # A tibble: 5 x 5 col     row   col   expected     actual                                                      file expected   <int> <chr>      <chr>      <chr>                                                     <chr> actual 1     1  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_5_1510425176.csv' file 2     2  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_5_1510425176.csv' row 3     3  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_5_1510425176.csv' col 4     4  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_5_1510425176.csv' expected 5     5  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_5_1510425176.csv'
... ................. ... ............................................................................................. ........ ............................................................................................. ...... ......................... [... truncated]
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_logical(),
  V5 = col_integer(),
  V6 = col_character(),
  V7 = col_double(),
  V8 = col_character(),
  V9 = col_integer(),
  V10 = col_character(),
  V11 = col_integer()
)
Warning: 3200 parsing failures.
row # A tibble: 5 x 5 col     row   col   expected     actual                                                      file expected   <int> <chr>      <chr>      <chr>                                                     <chr> actual 1     1  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_6_1510425176.csv' file 2     2  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_6_1510425176.csv' row 3     3  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_6_1510425176.csv' col 4     4  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_6_1510425176.csv' expected 5     5  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_6_1510425176.csv'
... ................. ... ............................................................................................. ........ ............................................................................................. ...... ......................... [... truncated]
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_logical(),
  V5 = col_integer(),
  V6 = col_character(),
  V7 = col_double(),
  V8 = col_character(),
  V9 = col_integer(),
  V10 = col_character(),
  V11 = col_integer()
)
Warning: 3200 parsing failures.
row # A tibble: 5 x 5 col     row   col   expected     actual                                                      file expected   <int> <chr>      <chr>      <chr>                                                     <chr> actual 1     1  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_7_1510425176.csv' file 2     2  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_7_1510425176.csv' row 3     3  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_7_1510425176.csv' col 4     4  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_7_1510425176.csv' expected 5     5  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_7_1510425176.csv'
... ................. ... ............................................................................................. ........ ............................................................................................. ...... ......................... [... truncated]
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_logical(),
  V5 = col_integer(),
  V6 = col_character(),
  V7 = col_double(),
  V8 = col_character(),
  V9 = col_integer(),
  V10 = col_character(),
  V11 = col_integer()
)
Warning: 3200 parsing failures.
row # A tibble: 5 x 5 col     row   col   expected     actual                                                      file expected   <int> <chr>      <chr>      <chr>                                                     <chr> actual 1     1  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_8_1510425176.csv' file 2     2  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_8_1510425176.csv' row 3     3  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_8_1510425176.csv' col 4     4  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_8_1510425176.csv' expected 5     5  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_8_1510425176.csv'
... ................. ... ............................................................................................. ........ ............................................................................................. ...... ......................... [... truncated]
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_logical(),
  V5 = col_integer(),
  V6 = col_character(),
  V7 = col_double(),
  V8 = col_character(),
  V9 = col_integer(),
  V10 = col_character(),
  V11 = col_integer()
)
Warning: 3200 parsing failures.
row # A tibble: 5 x 5 col     row   col   expected     actual                                                      file expected   <int> <chr>      <chr>      <chr>                                                     <chr> actual 1     1  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_9_1510425176.csv' file 2     2  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_9_1510425176.csv' row 3     3  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_9_1510425176.csv' col 4     4  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_9_1510425176.csv' expected 5     5  <NA> 11 columns 12 columns 'bench_queries_region_twitter_1000_1000_9_1510425176.csv'
... ................. ... ............................................................................................. ........ ............................................................................................. ...... ......................... [... truncated]
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_logical(),
  V5 = col_integer(),
  V6 = col_character(),
  V7 = col_double(),
  V8 = col_character(),
  V9 = col_integer(),
  V10 = col_character(),
  V11 = col_integer()
)
Warning: 3200 parsing failures.
row # A tibble: 5 x 5 col     row   col   expected     actual                                                       file expected   <int> <chr>      <chr>      <chr>                                                      <chr> actual 1     1  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_10_1510425176.csv' file 2     2  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_10_1510425176.csv' row 3     3  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_10_1510425176.csv' col 4     4  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_10_1510425176.csv' expected 5     5  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_10_1510425176.csv'
... ................. ... .............................................................................................. ........ .............................................................................................. ...... ................ [... truncated]
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_logical(),
  V5 = col_integer(),
  V6 = col_character(),
  V7 = col_double(),
  V8 = col_character(),
  V9 = col_integer(),
  V10 = col_character(),
  V11 = col_integer()
)
Warning: 3200 parsing failures.
row # A tibble: 5 x 5 col     row   col   expected     actual                                                       file expected   <int> <chr>      <chr>      <chr>                                                      <chr> actual 1     1  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_11_1510425176.csv' file 2     2  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_11_1510425176.csv' row 3     3  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_11_1510425176.csv' col 4     4  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_11_1510425176.csv' expected 5     5  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_11_1510425176.csv'
... ................. ... .............................................................................................. ........ .............................................................................................. ...... ................ [... truncated]
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_logical(),
  V5 = col_integer(),
  V6 = col_character(),
  V7 = col_double(),
  V8 = col_character(),
  V9 = col_integer(),
  V10 = col_character(),
  V11 = col_double()
)
Warning: 3200 parsing failures.
row # A tibble: 5 x 5 col     row   col   expected     actual                                                      file expected   <int> <chr>      <chr>      <chr>                                                     <chr> actual 1     1  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_1_1510425176.csv' file 2     2  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_1_1510425176.csv' row 3     3  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_1_1510425176.csv' col 4     4  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_1_1510425176.csv' expected 5     5  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_1_1510425176.csv'
... ................. ... ............................................................................................. ........ ............................................................................................. ...... ......................... [... truncated]
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_logical(),
  V5 = col_integer(),
  V6 = col_character(),
  V7 = col_double(),
  V8 = col_character(),
  V9 = col_integer(),
  V10 = col_character(),
  V11 = col_integer()
)
Warning: 3200 parsing failures.
row # A tibble: 5 x 5 col     row   col   expected     actual                                                       file expected   <int> <chr>      <chr>      <chr>                                                      <chr> actual 1     1  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_12_1510425176.csv' file 2     2  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_12_1510425176.csv' row 3     3  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_12_1510425176.csv' col 4     4  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_12_1510425176.csv' expected 5     5  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_12_1510425176.csv'
... ................. ... .............................................................................................. ........ .............................................................................................. ...... ................ [... truncated]
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_logical(),
  V5 = col_integer(),
  V6 = col_character(),
  V7 = col_double(),
  V8 = col_character(),
  V9 = col_integer(),
  V10 = col_character(),
  V11 = col_integer()
)
Warning: 3200 parsing failures.
row # A tibble: 5 x 5 col     row   col   expected     actual                                                       file expected   <int> <chr>      <chr>      <chr>                                                      <chr> actual 1     1  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_13_1510425176.csv' file 2     2  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_13_1510425176.csv' row 3     3  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_13_1510425176.csv' col 4     4  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_13_1510425176.csv' expected 5     5  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_13_1510425176.csv'
... ................. ... .............................................................................................. ........ .............................................................................................. ...... ................ [... truncated]
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_logical(),
  V5 = col_integer(),
  V6 = col_character(),
  V7 = col_double(),
  V8 = col_character(),
  V9 = col_integer(),
  V10 = col_character(),
  V11 = col_integer()
)
Warning: 3200 parsing failures.
row # A tibble: 5 x 5 col     row   col   expected     actual                                                       file expected   <int> <chr>      <chr>      <chr>                                                      <chr> actual 1     1  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_14_1510425176.csv' file 2     2  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_14_1510425176.csv' row 3     3  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_14_1510425176.csv' col 4     4  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_14_1510425176.csv' expected 5     5  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_14_1510425176.csv'
... ................. ... .............................................................................................. ........ .............................................................................................. ...... ................ [... truncated]
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_logical(),
  V5 = col_integer(),
  V6 = col_character(),
  V7 = col_double(),
  V8 = col_character(),
  V9 = col_integer(),
  V10 = col_character(),
  V11 = col_double()
)
Warning: 3200 parsing failures.
row # A tibble: 5 x 5 col     row   col   expected     actual                                                      file expected   <int> <chr>      <chr>      <chr>                                                     <chr> actual 1     1  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_2_1510425176.csv' file 2     2  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_2_1510425176.csv' row 3     3  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_2_1510425176.csv' col 4     4  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_2_1510425176.csv' expected 5     5  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_2_1510425176.csv'
... ................. ... ............................................................................................. ........ ............................................................................................. ...... ......................... [... truncated]
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_logical(),
  V5 = col_integer(),
  V6 = col_character(),
  V7 = col_double(),
  V8 = col_character(),
  V9 = col_integer(),
  V10 = col_character(),
  V11 = col_double()
)
Warning: 3200 parsing failures.
row # A tibble: 5 x 5 col     row   col   expected     actual                                                      file expected   <int> <chr>      <chr>      <chr>                                                     <chr> actual 1     1  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_3_1510425176.csv' file 2     2  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_3_1510425176.csv' row 3     3  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_3_1510425176.csv' col 4     4  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_3_1510425176.csv' expected 5     5  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_3_1510425176.csv'
... ................. ... ............................................................................................. ........ ............................................................................................. ...... ......................... [... truncated]
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_logical(),
  V5 = col_integer(),
  V6 = col_character(),
  V7 = col_double(),
  V8 = col_character(),
  V9 = col_integer(),
  V10 = col_character(),
  V11 = col_double()
)
Warning: 3200 parsing failures.
row # A tibble: 5 x 5 col     row   col   expected     actual                                                      file expected   <int> <chr>      <chr>      <chr>                                                     <chr> actual 1     1  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_4_1510425176.csv' file 2     2  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_4_1510425176.csv' row 3     3  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_4_1510425176.csv' col 4     4  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_4_1510425176.csv' expected 5     5  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_4_1510425176.csv'
... ................. ... ............................................................................................. ........ ............................................................................................. ...... ......................... [... truncated]
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_logical(),
  V5 = col_integer(),
  V6 = col_character(),
  V7 = col_double(),
  V8 = col_character(),
  V9 = col_integer(),
  V10 = col_character(),
  V11 = col_integer()
)
Warning: 3200 parsing failures.
row # A tibble: 5 x 5 col     row   col   expected     actual                                                      file expected   <int> <chr>      <chr>      <chr>                                                     <chr> actual 1     1  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_5_1510425176.csv' file 2     2  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_5_1510425176.csv' row 3     3  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_5_1510425176.csv' col 4     4  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_5_1510425176.csv' expected 5     5  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_5_1510425176.csv'
... ................. ... ............................................................................................. ........ ............................................................................................. ...... ......................... [... truncated]
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_logical(),
  V5 = col_integer(),
  V6 = col_character(),
  V7 = col_double(),
  V8 = col_character(),
  V9 = col_integer(),
  V10 = col_character(),
  V11 = col_integer()
)
Warning: 3200 parsing failures.
row # A tibble: 5 x 5 col     row   col   expected     actual                                                      file expected   <int> <chr>      <chr>      <chr>                                                     <chr> actual 1     1  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_6_1510425176.csv' file 2     2  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_6_1510425176.csv' row 3     3  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_6_1510425176.csv' col 4     4  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_6_1510425176.csv' expected 5     5  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_6_1510425176.csv'
... ................. ... ............................................................................................. ........ ............................................................................................. ...... ......................... [... truncated]
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_logical(),
  V5 = col_integer(),
  V6 = col_character(),
  V7 = col_double(),
  V8 = col_character(),
  V9 = col_integer(),
  V10 = col_character(),
  V11 = col_integer()
)
Warning: 3200 parsing failures.
row # A tibble: 5 x 5 col     row   col   expected     actual                                                      file expected   <int> <chr>      <chr>      <chr>                                                     <chr> actual 1     1  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_7_1510425176.csv' file 2     2  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_7_1510425176.csv' row 3     3  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_7_1510425176.csv' col 4     4  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_7_1510425176.csv' expected 5     5  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_7_1510425176.csv'
... ................. ... ............................................................................................. ........ ............................................................................................. ...... ......................... [... truncated]
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_logical(),
  V5 = col_integer(),
  V6 = col_character(),
  V7 = col_double(),
  V8 = col_character(),
  V9 = col_integer(),
  V10 = col_character(),
  V11 = col_integer()
)
Warning: 3200 parsing failures.
row # A tibble: 5 x 5 col     row   col   expected     actual                                                      file expected   <int> <chr>      <chr>      <chr>                                                     <chr> actual 1     1  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_8_1510425176.csv' file 2     2  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_8_1510425176.csv' row 3     3  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_8_1510425176.csv' col 4     4  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_8_1510425176.csv' expected 5     5  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_8_1510425176.csv'
... ................. ... ............................................................................................. ........ ............................................................................................. ...... ......................... [... truncated]
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_logical(),
  V5 = col_integer(),
  V6 = col_character(),
  V7 = col_double(),
  V8 = col_character(),
  V9 = col_integer(),
  V10 = col_character(),
  V11 = col_integer()
)
Warning: 3200 parsing failures.
row # A tibble: 5 x 5 col     row   col   expected     actual                                                      file expected   <int> <chr>      <chr>      <chr>                                                     <chr> actual 1     1  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_9_1510425176.csv' file 2     2  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_9_1510425176.csv' row 3     3  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_9_1510425176.csv' col 4     4  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_9_1510425176.csv' expected 5     5  <NA> 11 columns 12 columns 'bench_queries_region_twitter_2000_1000_9_1510425176.csv'
... ................. ... ............................................................................................. ........ ............................................................................................. ...... ......................... [... truncated]
There were 28 warnings (use warnings() to see them)
#+end_example

Remove useless columns
#+begin_src R :results output :exports both :session 

names(df) <- c("algo" , "V2" , "queryId",  "V4" , "T"  ,"bench" , "ms" , "V8", "refinements" , "V10", "Count", "refLevel")

df <- select(df, -V2, -V4, -V8, -V10)

str(df)
#+end_src

#+RESULTS:
: Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	89600 obs. of  8 variables:
:  $ algo       : chr  "GeoHashBinary" "GeoHashBinary" "GeoHashBinary" "GeoHashBinary" ...
:  $ queryId    : int  0 0 0 0 0 0 0 0 0 0 ...
:  $ T          : int  1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ...
:  $ bench      : chr  "apply_at_region" "apply_at_region" "apply_at_region" "apply_at_region" ...
:  $ ms         : num  0.357 0.355 0.361 0.353 0.352 ...
:  $ refinements: int  69 69 69 69 69 69 69 69 69 69 ...
:  $ Count      : num  924827 924827 924827 924827 924827 ...
:  $ refLevel   : Factor w/ 14 levels "10","11","1",..: 1 1 1 1 1 1 1 1 1 1 ...

Summarize the averages
#+begin_src R :results output :session :exports both
dfplot <- 
    df %>% 
    group_by_at(vars(-ms, -refinements)) %>%   #group_by all expect ms
    summarize(avg_ms = mean(ms), stdv = sd(ms)) %>%
    mutate(refLevel = as.integer(as.character(refLevel))) %>%
    arrange(refLevel) %>%
    filter(T == 1000)

dfplot
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 4,480 x 8
# Groups:   algo, queryId, T, bench, Count [908]
    algo queryId     T           bench  Count refLevel   avg_ms       stdv
   <chr>   <int> <int>           <chr>  <dbl>    <int>    <dbl>      <dbl>
 1 BTree       0  1000 apply_at_region 924827        1 17.88266 0.31246492
 2 BTree       0  1000  scan_at_region     NA        1 24.76905 0.01259605
 3 BTree       1  1000 apply_at_region 929918        1 17.78989 0.26006714
 4 BTree       1  1000  scan_at_region     NA        1 24.80026 0.02786073
 5 BTree       2  1000 apply_at_region 753921        1 17.52672 0.10294663
 6 BTree       2  1000  scan_at_region     NA        1 23.90354 0.01953829
 7 BTree       3  1000 apply_at_region 989228        1 17.62055 0.07342717
 8 BTree       3  1000  scan_at_region     NA        1 25.12633 0.03318695
 9 BTree       4  1000 apply_at_region 929320        1 18.92725 2.73186005
10 BTree       4  1000  scan_at_region     NA        1 25.58921 2.18233342
# ... with 4,470 more rows
#+end_example


PLot time Vs RefLevel
#+begin_src R :results output graphics :file (org-babel-temp-file "figure" ".png") :exports both :width 600 :height 400 :session 

dfplot %>% 
    filter( T == 1000) %>%
#    mutate(queryW = queryId %/% 10) 
#    filter(queryId < 10) %>%
    ggplot(aes(x = refLevel,avg_ms,color=as.factor(queryId))) + 
 #   geom_errorbar(aes(ymin = avg_ms - stdv, ymax = avg_ms + stdv) ) +
    geom_line() +
    scale_x_continuous(breaks=seq(0, 14, by=1)) +
    facet_grid(bench~algo) 
  #  facet_wrap(algo~bench,nrow=2)

#+end_src

#+RESULTS:
[[file:/tmp/babel-17282Hv/figure1728_0R.png]]

Note the the smaller queryIDs have a larger area of selection 
[[file:~/Projects/pmq/data/queriesLHS.org::*Coordinates%20LHS%20To%20avoid%20out-of-bound%20queries%20+%20LAPPLY%20+%20RBIND][Coordinates LHS To avoid out-of-bound queries + LAPPLY + RBIND]]


Group by query width
#+begin_src R :results output :exports both :session 

dfplot %>% 
    mutate(queryW = queryId %/% 10) %>%
    group_by(algo,queryW,bench,refLevel) %>%
    summarize(time = mean(avg_ms), sdtdv = sd(avg_ms))

#+end_src

#+RESULTS:
#+begin_example
# A tibble: 448 x 6
# Groups:   algo, queryW, bench [?]
    algo queryW           bench refLevel     time     sdtdv
   <chr>  <dbl>           <chr>    <int>    <dbl>     <dbl>
 1 BTree      0 apply_at_region        1 17.77716 0.4177340
 2 BTree      0 apply_at_region        2 17.61552 0.3825027
 3 BTree      0 apply_at_region        3 14.08434 1.3392955
 4 BTree      0 apply_at_region        4 12.95060 1.6072631
 5 BTree      0 apply_at_region        5 12.00733 0.7700920
 6 BTree      0 apply_at_region        6 11.54523 0.4004386
 7 BTree      0 apply_at_region        7 10.72311 0.6150486
 8 BTree      0 apply_at_region        8 10.54572 0.5945493
 9 BTree      0 apply_at_region        9 10.51401 0.6934013
10 BTree      0 apply_at_region       10 10.65255 0.8656675
# ... with 438 more rows
#+end_example


#+begin_src R :results output graphics :file "./img/Reflevel.png" :exports both :width 600 :height 400 :session 

dfplot %>% 
    mutate(queryW = 90 / 2**(queryId %/% 10)) %>%
    group_by(algo,queryW,bench,refLevel) %>%
    summarize(time = mean(avg_ms), stdv = sd(avg_ms)) %>%
    ggplot(aes(x = refLevel,time,color=as.factor(queryW))) + 
 #   geom_errorbar(aes(ymin = time - stdv, ymax = time + stdv) ) +
    geom_line() +
    scale_x_continuous(breaks=seq(0, 14, by=1)) +
    scale_y_continuous(trans = scales::log2_trans()) +
    labs(colour="Query Width\n (Degrees)", y = "times ms (log2 scale)") +
    facet_grid(bench~algo)
  #  facet_wrap(algo~bench,nrow=2)

#+end_src

#+RESULTS:
[[file:./img/Reflevel.png]]


#+begin_src R :results output graphics :file "./img/refLevelAnalysis.pdf" :exports both :width 10 :height 5 :session :var path=(print default-directory)
setwd(path)


algo_labels <- c(BTree = "BTree", GeoHashBinary = "PMQ")

dfplot %>% 
    filter( bench == "scan_at_region", algo == "GeoHashBinary") %>% 
    mutate(queryW = 90 / 2**(queryId %/% 10)) %>%
    ggplot( aes(x = refLevel,avg_ms, color=as.factor(queryW), group=(queryId))) + 
    theme_bw() + 
    geom_line() +
    geom_vline(xintercept=8, linetype="dashed") + 
    scale_x_continuous(breaks=seq(0, 14, by=1)) +
    scale_y_continuous(trans = scales::log2_trans(),
                       labels = scales::trans_format("log2", scales::math_format(2^.x))) +
    labs(colour="Query Width (Degrees)", 
         y = "Query execution time in (ms)" ,
         x = "Geohash refinement level") +
    facet_wrap(~queryW,
               scale="fixed",
               labeller = labeller(algo=algo_labels))+
    theme(legend.position = "bottom",
          axis.text = element_text(size = 12),
          axis.title = element_text(size = 14),
          legend.text = element_text( size = 12),
          legend.title = element_text( size = 12),
          strip.text = element_text( size = 12)) +
    guides(color=guide_legend(nrow=1,byrow=TRUE))

#+end_src

#+RESULTS:
[[file:./img/refLevelAnalysis.pdf]]

** Conclusions

+We can justify that we verify in our experiments that Z = 8 gives in general the best performance.+

+Z  = number of quadtree refinements of the query algorithm+

In the case of irregular dataset there is no best threshold for every one. 

