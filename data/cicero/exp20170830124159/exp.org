# -*- org-export-babel-evaluate: t; -*-
#+TITLE: Experiment Diary
#+LANGUAGE: en 
#+STARTUP: indent
#+STARTUP: logdrawer hideblocks
#+SEQ_TODO: TODO INPROGRESS(i) | DONE DEFERRED(@) CANCELED(@)
#+TAGS: @JULIO(J)
#+TAGS: IMPORTANT(i) TEST(t) DEPRECATED(d) noexport(n) ignore(n) export(e)
#+CATEGORY: exp
#+OPTIONS: ^:{} todo:nil H:4
#+PROPERTY: header-args :cache no :eval no-export 


* DONE Description 

Test the queries on uniform data. 
And compare the folling performances 

- PMQ / GEOHASH
- BTREE 
- RTREE

Use the refinement level = 8 

** Standalone script 
To generate the results outside emacs and orgmode you can use the standalone scripts, generated from the tangled source blocks in this file

- parse.sh : parse the results to CSV
- plotResults.R : generate the plots 
  

* DONE Experiment Script
** DONE Initial Setup 

#+begin_src sh :results value :exports both
expId=$(basename $(pwd))
echo $expId
#+end_src

#+NAME: expId
#+RESULTS:
: exp20170830124159

Set up git branch
#+begin_src sh :results output :exports both
git checkout master
#+end_src

#+RESULTS:
: M	LabBook.org
: M	include/BTreeCtn.cpp
: M	include/GeoHash.cpp

Create EXP branch
#+begin_src sh :results output :exports both :var expId=expId
git checkout -b $expId
#+end_src

#+RESULTS:
: M	LabBook.org
: M	include/BTreeCtn.cpp
: M	include/GeoHash.cpp

Commit branch
#+begin_src sh :results output :exports both :var expId=expId
git status .
git add exp.org
git commit -m "Initial commit for $expId"
#+end_src

#+RESULTS:
#+begin_example
On branch exp20170830124159
Untracked files:
  (use "git add <file>..." to include in what will be committed)

	.#exp.org
	exp.org
	output.csv
	output.log

nothing added to commit but untracked files present (use "git add" to track)
[exp20170830124159 3d30984] Initial commit for exp20170830124159
 1 file changed, 588 insertions(+)
 create mode 100644 data/cicero/exp20170830124159/exp.org
#+end_example

#+begin_src sh :results output :exports both :var expId=expId
git la -3 
#+end_src

#+RESULTS:
: * 94ef664 (HEAD -> exp20170830124159) upd: disable refinements log
: * 3d30984 Initial commit for exp20170830124159
: * 381743e (master) print parameter

** DONE Export run script 

Use C-u C-c C-v t to tangle this script 
#+begin_src sh :results output :exports both :tangle run.sh :shebang #!/bin/bash :eval never :var expId=expId
set -e
# Any subsequent(*) commands which fail will cause the shell script to exit immediately
echo $(hostname) 

##########################################################
### SETUP THIS VARIABLES

BUILDIR=~/Projects/pmq/build-release
PMABUILD_DIR=~/Projects/hppsimulations/build-release
DATADIR=$(pwd)
# workaround as :var arguments are not been correctly tangled by my orgmode
#expId=$(basename $(pwd) | sed 's/exp//g')
expId=$(basename $(pwd))
TMPDIR=/dev/shm/$expId

# generate output name
if [ $1 ] ; then 
    EXECID=$1
else
    EXECID=$(date +%s)
fi

#########################################################

mkdir -p $TMPDIR
#mkdir -p $DATADIR

# make pma
mkdir -p $PMABUILD_DIR
cd $PMABUILD_DIR
cmake -DCMAKE_BUILD_TYPE="Release" -DTWITTERVIS=ON -DRHO_INIT=OFF ../pma_cd
make 

# make twitterVis
mkdir -p $BUILDIR
cd $BUILDIR 
cmake -DPMA_BUILD_DIR=$PMABUILD_DIR -DCMAKE_BUILD_TYPE="Release" ..
make

#get machine configuration
echo "" > $DATADIR/info.org
~/Projects/pmq/scripts/g5k_get_info.sh $DATADIR/info.org 

# EXECUTE BENCHMARK

#Continue execution even if one these fails
set +e 

#Run queris
t=10000
b=100
#n=$(($t*$b))
ref=8
stdbuf -oL ./benchmarks/bench_queries_region -seed 123 -rate 100 -x 10 -rate ${b} -min_t ${t} -max_t ${t} -ref ${ref} -bf ../data/queriesLHS.csv >  ${TMPDIR}/bench_queries_region_random_${t}_${b}_${ref}_${EXECID}.log

set -e

cd $TMPDIR
tar -cvzf log_$EXECID.tgz *_$EXECID.log

cd $DATADIR
cp $TMPDIR/log_$EXECID.tgz .

git checkout $expId

git add info.org log_$EXECID.tgz run.sh 
git add -u
git commit -m "Finish execution $EXECID"
git push origin $expId
#+end_src 


** DONE Commit local changes
#+begin_src sh :results output :exports both
git status .
#+end_src

#+RESULTS:
#+begin_example
On branch exp20170830124159
Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git checkout -- <file>..." to discard changes in working directory)

	modified:   exp.org

Untracked files:
  (use "git add <file>..." to include in what will be committed)

	.#exp.org
	output.csv
	output.log
	run.sh

no changes added to commit (use "git add" and/or "git commit -a")
#+end_example

#+begin_src sh :results output :exports both
git add run.sh exp.org
git commit -m "UPD: run.sh script"
#git commit --amend -m "UPD: run.sh script"
#+end_src

#+RESULTS:
: [exp20170830124159 8f2bf8f] UPD: run.sh script
:  2 files changed, 92 insertions(+), 15 deletions(-)
:  create mode 100755 data/cicero/exp20170830124159/run.sh

Push to remote
#+begin_src sh :results output :exports both :var expId=expId
#git push bitbucket $expId
git push origin $expId
#+end_src

#+RESULTS:

** CANCELED Local Execution                                          :local:
:LOGBOOK:
- State "CANCELED"   from "TODO"       [2017-09-05 Ter 19:00]
:END:

#+begin_src sh :results output :exports both :session local :var expId=expId
cd ~/Projects/pmq/data/$(hostname)/$expId
runid=$(date +%s)
tmux new -d -s runExp "cd ~/Projects/pmq/data/$(hostname)/$expId; ./run.sh ${runid} &> run_${runid}"
git add run_$runid
echo $runid
#+end_src

Check process running
#+begin_src sh :results output :exports both :session remote
tmux ls
ps ux
#+end_src

** DONE Remote Execution                                            :remote:

*** Get new changes on remote                                      :remote:
#+begin_src sh :session remote :results output :exports both 
ssh -A cicero
#+end_src

#+RESULTS:
#+begin_example

Welcome to Ubuntu 16.04.3 LTS (GNU/Linux 4.4.0-92-generic x86_64)

 ,* Documentation:  https://help.ubuntu.com
 ,* Management:     https://landscape.canonical.com
 ,* Support:        https://ubuntu.com/advantage

27 packages can be updated.
0 updates are security updates.

,*** System restart required ***
Last login: Mon Sep  4 19:50:32 2017 from 143.54.13.218
#+end_example

Get the last script on the remote machine (require entering a password
for bitbucket)
#+begin_src sh :session remote :results output :exports both :var expId=expId
cd ~/Projects/pmq/
git config --add remote.origin.fetch refs/heads/$expId:refs/remotes/origin/$expId
git fetch origin $expId
git checkout $expId
git pull origin $expId
git log -1 | cat 
#+end_src

#+RESULTS:
#+begin_example

julio@cicero:~/Projects/pmq$ julio@cicero:~/Projects/pmq$ From bitbucket.org:jtoss/pmq
FETCH_HEAD
Already on 'exp20170830124159'
Your branch is up-to-date with 'origin/exp20170830124159'.
From bitbucket.org:jtoss/pmq
FETCH_HEAD
Already up-to-date.
commit 8f2bf8f9949702720b2f3ba24d60ed6e4d3968a9
Date:   Tue Sep 5 18:59:16 2017 -0300

    UPD: run.sh script
#+end_example

Update PMA repository on exp machine
#+begin_src sh :session remote :results output :exports both :var expId=expId
cd ~/Projects/hppsimulations/
git pull origin PMA_2016
git log -1 | cat
#+end_src

#+RESULTS:
: 
: julio@cicero:~/Projects/hppsimulations$ From bitbucket.org:joaocomba/pma
: FETCH_HEAD
: Already up-to-date.
: commit 011775f5fdeaeeff330da7df39751d9c5323b570
: Date:   Mon Feb 13 12:20:46 2017 -0200
: 
:     Bugfix: corrected pointer casts

*** DONE Execute Remotely                                          :remote:

Opens ssh connection and a tmux session

#+begin_src sh :results output :exports both :session remote :var expId=expId
cd ~/Projects/pmq/data/cicero/$expId
runid=$(date +%s)
tmux new -d -s runExp "cd ~/Projects/pmq/data/cicero/$expId; ./run.sh ${runid} &> run_${runid}"
git add run_$runid
echo $runid
#+end_src

#+RESULTS:
: 
: julio@cicero:~/Projects/pmq/data/cicero/exp20170830124159$ julio@cicero:~/Projects/pmq/data/cicero/exp20170830124159$ julio@cicero:~/Projects/pmq/data/cicero/exp20170830124159$ julio@cicero:~/Projects/pmq/data/cicero/exp20170830124159$ 1504649431

Check process running
#+begin_src sh :results output :exports both :session remote
tmux ls
ps ux
#+end_src

#+RESULTS:
: no server running on /tmp/tmux-1001/default
: USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
: julio    20570  0.0  0.0  45248  4692 ?        Ss   18:59   0:00 /lib/systemd/sy
: julio    20571  0.0  0.0 145408  2160 ?        S    18:59   0:00 (sd-pam)
: julio    20662  0.0  0.0  97464  3408 ?        S    18:59   0:00 sshd: julio@pts
: julio    20665  0.0  0.0  22684  5224 pts/18   Ss   18:59   0:00 -bash
: julio    21836  0.0  0.0  37368  3276 pts/18   R+   19:12   0:00 ps ux

**** DONE Pull local 
#+begin_src sh :results output :exports both :var expId=expId
#git commit -a -m "wip"
git status
git pull origin $expId
#+end_src

#+RESULTS:
#+begin_example
On branch exp20170830124159
Untracked files:
  (use "git add <file>..." to include in what will be committed)

	../../../LabBook.org.bkp
	../../../build-debug/
	.#exp.org
	output.csv
	output.log
	../exp20170904152622/
	../exp20170904153555/
	../../../include/types.h.orig

nothing added to commit but untracked files present (use "git add" to track)
Merge made by the 'recursive' strategy.
 data/cicero/exp20170830124159/info.org           | 697 +++++++++++++++++++++++
 data/cicero/exp20170830124159/log_1504649431.tgz | Bin 0 -> 25122 bytes
 data/cicero/exp20170830124159/run_1504649431     |  80 +++
 3 files changed, 777 insertions(+)
 create mode 100644 data/cicero/exp20170830124159/info.org
 create mode 100644 data/cicero/exp20170830124159/log_1504649431.tgz
 create mode 100644 data/cicero/exp20170830124159/run_1504649431
#+end_example


* Analisys
** DONE Generate csv files
:PROPERTIES: 
:HEADER-ARGS:sh: :tangle parse.sh :shebang #!/bin/bash
:END:      

List logFiles
#+begin_src sh :results table :exports both
ls -htl *tgz
#+end_src

#+RESULTS:
| -rw-rw-r-- 1 julio julio 25K Set  5 19:14 log_1504649431.tgz |

#+NAME: logFile
#+begin_src sh :results output :exports both 
tar xvzf log_*.tgz
#+end_src

#+RESULTS: logFile
: bench_queries_region_random_10000_100_8_1504649431.log

Create CSV using logFile 
#+begin_src sh :results output :exports both :var logFile=logFile[0]
#echo $logFile
echo $(basename -s .log $logFile ).csv
grep "; query ;" $logFile | sed "s/QueryBench//g" >  $(basename -s .log $logFile ).csv
#+end_src

#+NAME: csvFile
#+RESULTS:
: bench_queries_region_random_10000_100_8_1504649431.csv

Create an director for images
#+begin_src sh :results output :exports both :tangle no
mkdir img
#+end_src

#+RESULTS:

** Results
:PROPERTIES: 
:HEADER-ARGS:R: :session *R* :tangle plotResults.R :shebang #!/usr/bin/env Rscript
:END:      

Load the CSV into R
#+begin_src R :results output :exports both :var f=csvFile
library(tidyverse)

df <- f %>% read_delim(delim=";",trim_ws = TRUE, col_names = paste("V",c(1:7),sep="") )
df
#+end_src

#+RESULTS:
#+begin_example
Loading tidyverse: ggplot2
Loading tidyverse: tibble
Loading tidyverse: tidyr
Loading tidyverse: readr
Loading tidyverse: purrr
Loading tidyverse: dplyr
Conflicts with tidy packages ---------------------------------------------------
filter(): dplyr, stats
lag():    dplyr, stats
Parsed with column specification:
cols(
  V1 = col_character(),
  V2 = col_character(),
  V3 = col_integer(),
  V4 = col_character(),
  V5 = col_double(),
  V6 = col_character(),
  V7 = col_integer()
)
Warning: 4800 parsing failures.
row # A tibble: 5 x 5 col     row   col  expected    actual expected   <int> <chr>     <chr>     <chr> actual 1     1  <NA> 7 columns 6 columns file 2     2  <NA> 7 columns 6 columns row 3     3  <NA> 7 columns 6 columns col 4     4  <NA> 7 columns 6 columns expected 5     5  <NA> 7 columns 6 columns actual # ... with 1 more variables: file <chr>
... ................. ... ................................. ........ ................................. ...... ................................. .... ................................. ... ................................. ... ................................. ........ ................................. ...... .......................................
See problems(...) for more details.

Warning message:
In rbind(names(probs), probs_f) :
  number of columns of result is not a multiple of vector length (arg 1)
# A tibble: 4,800 x 7
              V1    V2    V3             V4       V5    V6    V7
           <chr> <chr> <int>          <chr>    <dbl> <chr> <int>
 1 GeoHashBinary query     0 scan_at_region 0.785148  <NA>    NA
 2 GeoHashBinary query     0 scan_at_region 0.738641  <NA>    NA
 3 GeoHashBinary query     0 scan_at_region 0.732765  <NA>    NA
 4 GeoHashBinary query     0 scan_at_region 0.730181  <NA>    NA
 5 GeoHashBinary query     0 scan_at_region 0.733566  <NA>    NA
 6 GeoHashBinary query     0 scan_at_region 0.707500  <NA>    NA
 7 GeoHashBinary query     0 scan_at_region 0.666402  <NA>    NA
 8 GeoHashBinary query     0 scan_at_region 0.665990  <NA>    NA
 9 GeoHashBinary query     0 scan_at_region 0.671458  <NA>    NA
10 GeoHashBinary query     0 scan_at_region 0.672691  <NA>    NA
# ... with 4,790 more rows
#+end_example

Remove useless columns
#+begin_src R :results output :exports both :session 

names(df) <- c("algo" , "V2" , "queryId", "bench" , "ms" , "V6", "Count")

df <- select(df, -V2, -V6)
df
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 4,800 x 5
            algo queryId          bench       ms Count
           <chr>   <int>          <chr>    <dbl> <int>
 1 GeoHashBinary       0 scan_at_region 0.785148    NA
 2 GeoHashBinary       0 scan_at_region 0.738641    NA
 3 GeoHashBinary       0 scan_at_region 0.732765    NA
 4 GeoHashBinary       0 scan_at_region 0.730181    NA
 5 GeoHashBinary       0 scan_at_region 0.733566    NA
 6 GeoHashBinary       0 scan_at_region 0.707500    NA
 7 GeoHashBinary       0 scan_at_region 0.666402    NA
 8 GeoHashBinary       0 scan_at_region 0.665990    NA
 9 GeoHashBinary       0 scan_at_region 0.671458    NA
10 GeoHashBinary       0 scan_at_region 0.672691    NA
# ... with 4,790 more rows
#+end_example


Summary of the data frame
#+begin_src R :results output :session :exports both
summary(df[df$algo=="GeoHashBinary",])
summary(df[df$algo=="BTree",])
summary(df[df$algo=="RTree",])
#+end_src

#+RESULTS:
#+begin_example
     algo              queryId         bench                 ms          
 Length:1600        Min.   : 0.00   Length:1600        Min.   :0.000176  
 Class :character   1st Qu.:19.75   Class :character   1st Qu.:0.002171  
 Mode  :character   Median :39.50   Mode  :character   Median :0.015000  
                    Mean   :39.50                      Mean   :0.088030  
                    3rd Qu.:59.25                      3rd Qu.:0.064723  
                    Max.   :79.00                      Max.   :0.850964  
                                                                         
     Count          
 Min.   :     3.00  
 1st Qu.:    85.25  
 Median :  1246.00  
 Mean   : 22048.19  
 3rd Qu.: 14507.75  
 Max.   :132471.00  
 NA's   :800
     algo              queryId         bench                 ms          
 Length:1600        Min.   : 0.00   Length:1600        Min.   :0.000177  
 Class :character   1st Qu.:19.75   Class :character   1st Qu.:0.002205  
 Mode  :character   Median :39.50   Mode  :character   Median :0.016176  
                    Mean   :39.50                      Mean   :0.255601  
                    3rd Qu.:59.25                      3rd Qu.:0.148925  
                    Max.   :79.00                      Max.   :2.572940  
                                                                         
     Count          
 Min.   :     3.00  
 1st Qu.:    85.25  
 Median :  1246.00  
 Mean   : 22048.19  
 3rd Qu.: 14507.75  
 Max.   :132471.00  
 NA's   :800
     algo              queryId         bench                 ms          
 Length:1600        Min.   : 0.00   Length:1600        Min.   :0.000921  
 Class :character   1st Qu.:19.75   Class :character   1st Qu.:0.003528  
 Mode  :character   Median :39.50   Mode  :character   Median :0.015304  
                    Mean   :39.50                      Mean   :0.461009  
                    3rd Qu.:59.25                      3rd Qu.:0.186198  
                    Max.   :79.00                      Max.   :4.561880  
                                                                         
     Count          
 Min.   :     3.00  
 1st Qu.:    85.25  
 Median :  1246.00  
 Mean   : 22048.20  
 3rd Qu.: 14507.75  
 Max.   :132471.00  
 NA's   :800
#+end_example


Summarize the averages
#+begin_src R :results output :session :exports both
dfplot <- 
    df %>% 
    group_by_at(vars(-ms)) %>%   #group_by all expect ms
    summarize(avg_ms = mean(ms), stdv = sd(ms))

dfplot
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 480 x 6
# Groups:   algo, queryId, bench [?]
    algo queryId           bench  Count    avg_ms       stdv
   <chr>   <int>           <chr>  <int>     <dbl>      <dbl>
 1 BTree       0 apply_at_region 132363 1.0426081 0.08349100
 2 BTree       0  scan_at_region     NA 2.4059620 0.08163817
 3 BTree       1 apply_at_region 132280 0.9101590 0.03525793
 4 BTree       1  scan_at_region     NA 2.0293820 0.34071380
 5 BTree       2 apply_at_region 132084 1.1126400 0.07931612
 6 BTree       2  scan_at_region     NA 2.4221490 0.07268200
 7 BTree       3 apply_at_region 132291 0.9854236 0.05853645
 8 BTree       3  scan_at_region     NA 2.2746100 0.07655387
 9 BTree       4 apply_at_region 132312 0.9500366 0.04914609
10 BTree       4  scan_at_region     NA 2.1973110 0.09156773
# ... with 470 more rows
#+end_example

#+begin_src R :results output :exports both :session 
dfplot %>% filter(queryId == 10, bench == "scan_at_region", algo=="BTree") 
#+end_src

#+RESULTS:
: # A tibble: 1 x 6
: # Groups:   algo, queryId, bench [1]
:    algo queryId          bench Count    avg_ms       stdv
:   <chr>   <int>          <chr> <int>     <dbl>      <dbl>
: 1 BTree      10 scan_at_region    NA 0.3741499 0.03915504

Plot overview
#+begin_src R :results output graphics :file "./img/overview_query_region.png" :exports both :width 800 :height 600 :session 


myplot <- function(data) {
    data %>%
    #mutate(queryW = queryId %/% 10) %>%
    mutate(`Query Width` = 90 / 2**(queryId %/% 10)) %>%
#    arrange(desc(queryW)) %>%
    ggplot(aes(x = as.factor(queryId), y = avg_ms, color = algo)) + 
    geom_errorbar(aes(ymin = avg_ms - stdv, ymax = avg_ms + stdv) ) +
    geom_point() +
    #labs(title= data$bench) +     
#    scale_x_continuous(breaks=seq(0, 14, by=1)) +
    facet_wrap(bench~`Query Width`,scale="free", labeller = "label_both") + 
#    facet_wrap(~queryW,scale="free", labeller = "label_both") + 
#    facet_grid(queryW~bench,scale="free") + 
    theme(legend.position = "bottom",)
}
#dfplot %>% filter(bench == "scan_at_region") %>% myplot()
#dfplot %>% filter(bench == "apply_at_region") %>% myplot()
dfplot %>% 
    myplot() 
#+end_src

#+RESULTS:
[[file:./img/overview_query_region.png]]

*** Conclusions

- PMQ shows its best benefits on large range queries
- for very small queries we are similar to othe Btree an Rtree

** What is the actual counts of elements per query ?: 

There is one query where th count differs for Rtree by on element
#+begin_src R :results output :exports both :session 
dfplot %>% 
    filter( bench== "apply_at_region") %>% 
    #group to see if every algo has same coubts
    group_by(queryId, bench) %>%
    summarize(c = mean(Count), s = sd(Count)  ) %>% filter ( s > 0)  

dfplot %>% filter(queryId == 20)
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 1 x 4
# Groups:   queryId [1]
  queryId           bench        c         s
    <int>           <chr>    <dbl>     <dbl>
1      20 apply_at_region 8154.333 0.5773503
# A tibble: 6 x 6
# Groups:   algo, queryId, bench [6]
           algo queryId           bench Count    avg_ms         stdv
          <chr>   <int>           <chr> <int>     <dbl>        <dbl>
1         BTree      20 apply_at_region  8154 0.0678552 0.0036170891
2         BTree      20  scan_at_region    NA 0.1007520 0.0056617701
3 GeoHashBinary      20 apply_at_region  8154 0.0334573 0.0023895598
4 GeoHashBinary      20  scan_at_region    NA 0.0498771 0.0028642236
5         RTree      20 apply_at_region  8155 0.0998077 0.0007759466
6         RTree      20  scan_at_region    NA 0.1499539 0.0053384533
#+end_example

#+begin_src R :results output :exports both :session 
options(dplyr.width = Inf)
dfplot %>% 
    filter( bench == "apply_at_region") %>%
    ungroup( bench) %>% # must ungroup to drop the column
    select( -bench, -stdv) %>%
    gather(measure, value, Count, avg_ms) %>%
    unite(temp, algo, measure) %>%
    spread( temp, value) %>%
    as_tibble() %>%
    print(n = nrow(.))
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 80 x 7
   queryId BTree_avg_ms BTree_Count GeoHashBinary_avg_ms GeoHashBinary_Count RTree_avg_ms RTree_Count
 ,*   <int>        <dbl>       <dbl>                <dbl>               <dbl>        <dbl>       <dbl>
 1       0    1.0426081      132363            0.2037840              132363    1.8183480      132363
 2       1    0.9101590      132280            0.2416327              132280    1.7508900      132280
 3       2    1.1126400      132084            0.2711833              132084    1.7523560      132084
 4       3    0.9854236      132291            0.2287143              132291    1.8415490      132291
 5       4    0.9500366      132312            0.2323745              132312    1.8674060      132312
 6       5    1.0444628      132471            0.2187206              132471    1.7522920      132471
 7       6    0.9487325      132330            0.2488682              132330    1.7532490      132330
 8       7    0.9745518      132095            0.2187616              132095    1.8373120      132095
 9       8    0.8688792      132232            0.2186041              132232    1.6141160      132232
10       9    0.9460561      132144            0.2573925              132144    1.6276280      132144
11      10    0.2292115       33390            0.0783490               33390    0.2962927       33390
12      11    0.2212553       32941            0.0780191               32941    0.2420338       32941
13      12    0.2257064       33314            0.0760559               33314    0.2909577       33314
14      13    0.2557200       33137            0.1019111               33137    0.2692840       33137
15      14    0.2329901       33256            0.0808004               33256    0.3019309       33256
16      15    0.2324388       33111            0.0802684               33111    0.2376549       33111
17      16    0.2390114       33098            0.0838790               33098    0.2662903       33098
18      17    0.2314932       32822            0.0844051               32822    0.2062952       32822
19      18    0.2577060       33032            0.1004636               33032    0.2284387       33032
20      19    0.2310396       33295            0.0797515               33295    0.2665217       33295
21      20    0.0678552        8154            0.0334573                8154    0.0998077        8155
22      21    0.0702593        8333            0.0333716                8333    0.0979199        8333
23      22    0.0710358        8315            0.0347065                8315    0.0642748        8315
24      23    0.0720809        8311            0.0365934                8311    0.0719840        8311
25      24    0.0766017        8192            0.0374648                8192    0.0723196        8192
26      25    0.0736760        8127            0.0359640                8127    0.0863986        8127
27      26    0.0783671        8218            0.0392759                8218    0.0734920        8218
28      27    0.0786585        8333            0.0408821                8333    0.0607923        8333
29      28    0.0836931        8403            0.0440083                8403    0.0952383        8403
30      29    0.0729165        8183            0.0330339                8183    0.1069130        8183
31      30    0.0179516        2035            0.0169652                2035    0.0159808        2035
32      31    0.0301830        2130            0.0243284                2130    0.0175006        2130
33      32    0.0176269        2058            0.0153354                2058    0.0440493        2058
34      33    0.0213570        1963            0.0195343                1963    0.0271132        1963
35      34    0.0179458        2081            0.0149013                2081    0.0180261        2081
36      35    0.0172176        1975            0.0152589                1975    0.0154373        1975
37      36    0.0207823        2084            0.0187425                2084    0.0249510        2084
38      37    0.0185908        2079            0.0160189                2079    0.0154365        2079
39      38    0.0241236        2055            0.0212734                2055    0.0170222        2055
40      39    0.0188518        2019            0.0167951                2019    0.0185687        2019
41      40    0.0067703         509            0.0073513                 509    0.0092524         509
42      41    0.0089118         527            0.0090019                 527    0.0046692         527
43      42    0.0076295         519            0.0074422                 519    0.0061703         519
44      43    0.0084467         498            0.0086150                 498    0.0080847         498
45      44    0.0077735         521            0.0079684                 521    0.0068752         521
46      45    0.0175884         464            0.0170815                 464    0.0069983         464
47      46    0.0074878         523            0.0074183                 523    0.0125088         523
48      47    0.0191017         512            0.0181477                 512    0.0111560         512
49      48    0.0079213         513            0.0081270                 513    0.0065637         513
50      49    0.0069588         529            0.0067401                 529    0.0057790         529
51      50    0.0023504         126            0.0024698                 126    0.0058357         126
52      51    0.0038327         139            0.0043222                 139    0.0052998         139
53      52    0.0035994         136            0.0038301                 136    0.0030397         136
54      53    0.0021562         100            0.0022245                 100    0.0022661         100
55      54    0.0038772         135            0.0042329                 135    0.0028373         135
56      55    0.0064533         122            0.0066319                 122    0.0025843         122
57      56    0.0023988         152            0.0025701                 152    0.0055721         152
58      57    0.0055440         124            0.0063626                 124    0.0032938         124
59      58    0.0029288         137            0.0031200                 137    0.0060331         137
60      59    0.0039246         114            0.0045158                 114    0.0027009         114
61      60    0.0013719          30            0.0015612                  30    0.0027169          30
62      61    0.0012204          30            0.0013269                  30    0.0041714          30
63      62    0.0013704          21            0.0013727                  21    0.0032260          21
64      63    0.0024234          33            0.0026635                  33    0.0009686          33
65      64    0.0012554          41            0.0014584                  41    0.0027085          41
66      65    0.0021892          39            0.0024029                  39    0.0027298          39
67      66    0.0010218          30            0.0010391                  30    0.0027699          30
68      67    0.0013029          32            0.0014487                  32    0.0028457          32
69      68    0.0018087          36            0.0020268                  36    0.0021834          36
70      69    0.0017585          39            0.0018600                  39    0.0038034          39
71      70    0.0006130           6            0.0006230                   6    0.0020448           6
72      71    0.0011550           3            0.0012974                   3    0.0015886           3
73      72    0.0001859           7            0.0002210                   7    0.0018024           7
74      73    0.0013315          16            0.0014640                  16    0.0014068          16
75      74    0.0015132           8            0.0017134                   8    0.0027369           8
76      75    0.0014011          14            0.0015692                  14    0.0019752          14
77      76    0.0014812           6            0.0018275                   6    0.0022774           6
78      77    0.0017360          10            0.0019115                  10    0.0015728          10
79      78    0.0013188           4            0.0015203                   4    0.0015357           4
80      79    0.0007937           4            0.0008228                   4    0.0019735           4
#+end_example


